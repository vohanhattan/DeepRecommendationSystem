{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSSh9wlY4Xhz"
      },
      "source": [
        "# Recommender System based on Collaborative Filtering\n",
        "\n",
        "**Collaborative filtering** (CF) systems work by collecting user feedback in the form of ratings for items in a given domain and exploiting similarities in rating behavior among several users in determining how to recommend an item. The main advantage is that it requires no information about users or items and the more users interact with items the more new recommendations become accurate. However, as it only consider past interactions to make recommendations, collaborative filtering suffer from the **“cold start problem”**, which means that it is impossible to recommend anything to new users or to recommend a new item to any users and many users or items have too few interactions to be efficiently handled."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psd7JAck4Xh6"
      },
      "source": [
        "## Download Datasets\n",
        "\n",
        "In the project, I am planning to use [MovieLens]{https://grouplens.org/datasets/movielens/} as the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWowZppC4Xh7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import hashlib\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from os.path import isfile, isdir\n",
        "from urllib.request import urlretrieve\n",
        "from tensorflow.python.ops import math_ops\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WEjxctNz4Xh9",
        "outputId": "698b2c0f-8cd0-4012-c09f-e2121c90e954"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gv1H8v3b4Xh-"
      },
      "outputs": [],
      "source": [
        "def _unzip(save_path, _, database_name, data_path):\n",
        "    \"\"\"Unzip wrapper with the same interface as _ungzip\n",
        "    Args:\n",
        "        save_path: The path of the gzip files\n",
        "        database_name: Name of database\n",
        "        data_path: Path to extract to\n",
        "        _: HACK - Used to have to same interface as _ungzip\n",
        "    \"\"\"\n",
        "    print(f'Extracting { database_name }...')\n",
        "    with zipfile.ZipFile(save_path) as zf:\n",
        "        zf.extractall(data_path)\n",
        "\n",
        "def download_extract(database_name, data_path):\n",
        "    \"\"\"Download and extract database\n",
        "    Args:\n",
        "        database_name: Database name\n",
        "        data_path: Path to extract to\n",
        "    \"\"\"\n",
        "    DATASET_NAME = 'ml-1m'\n",
        "    if database_name == DATASET_NAME:\n",
        "        url = 'http://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
        "        hash_code = 'c4d9eecfca2ab87c1945afe126590906'\n",
        "        extract_path = os.path.join(data_path, DATASET_NAME)\n",
        "        save_path = os.path.join(data_path, f'{ DATASET_NAME }.zip')\n",
        "        extract_fn = _unzip\n",
        "        \n",
        "    if os.path.exists(extract_path):\n",
        "        print(f'Found { database_name } Data')\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(data_path)\n",
        "\n",
        "    if not os.path.exists(save_path):\n",
        "        with DLProgress(unit='B', unit_scale=True, miniters=1, desc=f'Downloading { database_name }') as pbar:\n",
        "            urlretrieve(url, save_path, pbar.hook)\n",
        "\n",
        "    assert hashlib.md5(open(save_path, 'rb').read()).hexdigest() == hash_code, \\\n",
        "        f'{ save_path } file is corrupted.  Remove the file and try again.'\n",
        "\n",
        "    os.makedirs(extract_path)\n",
        "    try:\n",
        "        extract_fn(save_path, extract_path, database_name, data_path)\n",
        "    except Exception as err:\n",
        "        shutil.rmtree(extract_path)  # Remove extraction folder if there is an error\n",
        "        raise err\n",
        "\n",
        "    print('Done downloading and extracing')\n",
        "    \n",
        "class DLProgress(tqdm):\n",
        "    \"\"\"Handle Progress Bar while Downloading\"\"\"\n",
        "    last_block = 0\n",
        "\n",
        "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
        "        \"\"\"\n",
        "        A hook function that will be called once on establishment of the network connection and\n",
        "        once after each block read thereafter.\n",
        "        Args:\n",
        "            block_num: A count of blocks transferred so far\n",
        "            block_size: Block size in bytes\n",
        "            total_size: The total size of the file. This may be -1 on older FTP servers which do not return\n",
        "                            a file size in response to a retrieval request.\n",
        "        \"\"\"\n",
        "        self.total = total_size\n",
        "        self.update((block_num - self.last_block) * block_size)\n",
        "        self.last_block = block_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7IPgUlF4XiA",
        "outputId": "558ba252-e0d1-49d4-bb4e-e76b3619ec50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading ml-1m: 5.92MB [00:00, 17.6MB/s]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ml-1m...\n",
            "Done downloading and extracing\n"
          ]
        }
      ],
      "source": [
        "data_dir = './'\n",
        "download_extract('ml-1m', data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvz53XUV4XiB"
      },
      "source": [
        "## View the Dataset\n",
        "\n",
        "The movie dataset includes three parts: users'data - **users.dat**, movies'data - **movies.dat**, ratings'data - **ratings.dat**\n",
        "\n",
        "### Uses' Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Vrp0ZYL94XiC",
        "outputId": "3427f942-0340-45ab-a01c-2069efb3965d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   UserID Gender  Age  OccupationID Zip-code\n",
              "0       1      F    1            10    48067\n",
              "1       2      M   56            16    70072\n",
              "2       3      M   25            15    55117\n",
              "3       4      M   45             7    02460\n",
              "4       5      M   25            20    55455"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce060889-009b-4141-a52e-d7ecfb39ee95\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>OccupationID</th>\n",
              "      <th>Zip-code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>F</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>48067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>56</td>\n",
              "      <td>16</td>\n",
              "      <td>70072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>M</td>\n",
              "      <td>25</td>\n",
              "      <td>15</td>\n",
              "      <td>55117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>M</td>\n",
              "      <td>45</td>\n",
              "      <td>7</td>\n",
              "      <td>02460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>M</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>55455</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce060889-009b-4141-a52e-d7ecfb39ee95')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce060889-009b-4141-a52e-d7ecfb39ee95 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce060889-009b-4141-a52e-d7ecfb39ee95');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "users_title = ['UserID', 'Gender', 'Age', 'OccupationID', 'Zip-code']\n",
        "users = pd.read_csv('./ml-1m/users.dat', sep='::', header=None, names=users_title, engine = 'python')\n",
        "users.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vobqYW6g4XiD"
      },
      "source": [
        "### Movies' Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "syH7lE2a4XiE",
        "outputId": "e18b0fab-4cfb-4c26-f498-a927a70aa583"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   MovieID                               Title                        Genres\n",
              "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
              "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
              "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
              "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
              "4        5  Father of the Bride Part II (1995)                        Comedy"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5685693-2588-403a-bbf6-27332a1d6cfd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MovieID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Animation|Children's|Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children's|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5685693-2588-403a-bbf6-27332a1d6cfd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5685693-2588-403a-bbf6-27332a1d6cfd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5685693-2588-403a-bbf6-27332a1d6cfd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "movies_title = ['MovieID', 'Title', 'Genres']\n",
        "movies = pd.read_csv('./ml-1m/movies.dat', sep='::', header=None, names=movies_title,encoding='latin-1', engine = 'python')\n",
        "movies.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8Bqox8z4XiF"
      },
      "source": [
        "### Ratings' Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Jq2_ABIH4XiF",
        "outputId": "ec5ca6f3-21b0-4ca5-8d33-6589357ac40a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   UserID  MovieID  Rating  timestamps\n",
              "0       1     1193       5   978300760\n",
              "1       1      661       3   978302109\n",
              "2       1      914       3   978301968\n",
              "3       1     3408       4   978300275\n",
              "4       1     2355       5   978824291"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-447c548e-ff2e-4695-bd35-d13e14b48005\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>MovieID</th>\n",
              "      <th>Rating</th>\n",
              "      <th>timestamps</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1193</td>\n",
              "      <td>5</td>\n",
              "      <td>978300760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>661</td>\n",
              "      <td>3</td>\n",
              "      <td>978302109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>914</td>\n",
              "      <td>3</td>\n",
              "      <td>978301968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3408</td>\n",
              "      <td>4</td>\n",
              "      <td>978300275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2355</td>\n",
              "      <td>5</td>\n",
              "      <td>978824291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-447c548e-ff2e-4695-bd35-d13e14b48005')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-447c548e-ff2e-4695-bd35-d13e14b48005 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-447c548e-ff2e-4695-bd35-d13e14b48005');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "ratings_title = ['UserID','MovieID', 'Rating', 'timestamps']\n",
        "ratings = pd.read_csv('./ml-1m/ratings.dat', sep='::', header=None, names=ratings_title,encoding='latin-1', engine = 'python')\n",
        "ratings.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiqFcnxY4XiG"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "1. Gender: change **F** to **0** and change **M** to **1**\n",
        "2. Age: transform to continous numbers from 0 to 7\n",
        "3. Genres: transform to digits\n",
        "4. Title: same as **Genres**\n",
        "\n",
        "Notes: The length of **Genres** and **Title** should be same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8tpQJof4XiG"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    \"\"\"Load dataset from file and then preprocessing it\"\"\"\n",
        "    # Load users' data\n",
        "    users_title = ['UserID', 'Gender', 'Age', 'JobID', 'Zip-code']\n",
        "    users = pd.read_csv('./ml-1m/users.dat', sep='::', header=None, names=users_title, encoding='latin-1',engine = 'python')\n",
        "    users = users.filter(regex='UserID|Gender|Age|JobID')\n",
        "    users_origin = users.values\n",
        "    # Preprocess users' gender and age attributes\n",
        "    gender_map = {'F':0, 'M':1}\n",
        "    users['Gender'] = users['Gender'].map(gender_map)\n",
        "    age_map = {val:idx for idx, val in enumerate(set(users['Age']))}\n",
        "    users['Age'] = users['Age'].map(age_map)\n",
        "    \n",
        "    # Load movies' data\n",
        "    movies_title = ['MovieID', 'Title', 'Genres']\n",
        "    movies = pd.read_csv('./ml-1m/movies.dat', sep='::', header=None, names=movies_title,encoding='latin-1', engine = 'python')\n",
        "    movies_origin = movies.values\n",
        "    # Remove year from title\n",
        "    pattern = re.compile(r'^(.*)\\((\\d+)\\)$')\n",
        "    title_map = {title:pattern.match(title).group(1) for title in set(movies['Title'])}\n",
        "    movies['Title'] = movies['Title'].map(title_map)\n",
        "    # Change movies' genre to dict with numbers\n",
        "    genres_set = set()\n",
        "    for val in movies['Genres'].str.split('|'):\n",
        "        genres_set.update(val)\n",
        "    genres_set.add('<PAD>')\n",
        "    genres2int = {val:idx for idx, val in enumerate(genres_set)}\n",
        "    genres_map = {val:[genres2int[row] for row in val.split('|')] for val in set(movies['Genres'])}\n",
        "    for key in genres_map:\n",
        "        for cnt in range(max(genres2int.values()) - len(genres_map[key])):\n",
        "            genres_map[key].insert(len(genres_map[key]) + cnt, genres2int['<PAD>'])\n",
        "    movies['Genres'] = movies['Genres'].map(genres_map)\n",
        "\n",
        "    # Change movies' title to dict with numbers\n",
        "    title_set = set()\n",
        "    for val in movies['Title'].str.split():\n",
        "        title_set.update(val)\n",
        "    title_set.add('<PAD>')\n",
        "    title2int = {val:idx for idx, val in enumerate(title_set)}\n",
        "    title_count = 15\n",
        "    title_map = {val:[title2int[row] for row in val.split()] for val in set(movies['Title'])}\n",
        "    for key in title_map:\n",
        "        for cnt in range(title_count - len(title_map[key])):\n",
        "            title_map[key].insert(len(title_map[key]) + cnt, title2int['<PAD>'])\n",
        "    movies['Title'] = movies['Title'].map(title_map)\n",
        "\n",
        "    # Load ratings' data\n",
        "    ratings_title = ['UserID','MovieID', 'ratings', 'timestamps']\n",
        "    ratings = pd.read_csv('./ml-1m/ratings.dat', sep='::', header=None, encoding='latin-1',names=ratings_title, engine = 'python')\n",
        "    ratings = ratings.filter(regex='UserID|MovieID|ratings')\n",
        "\n",
        "    # Merge\n",
        "    data = pd.merge(pd.merge(ratings, users), movies)\n",
        "    \n",
        "    # Split data into two parts\n",
        "    target_fields = ['ratings']\n",
        "    features_pd, targets_pd = data.drop(target_fields, axis=1), data[target_fields]\n",
        "    features = features_pd.values\n",
        "    targets_values = targets_pd.values\n",
        "    \n",
        "    return title_count, title_set, genres2int, features, targets_values, ratings, users, movies, data, movies_origin, users_origin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRYzIc0L4XiH"
      },
      "outputs": [],
      "source": [
        "title_count, title_set, genres2int, features, targets_values, ratings, users, movies, data, movies_origin, users_origin = load_data()\n",
        "pickle.dump((title_count, title_set, genres2int, features, targets_values, ratings, users, movies, data, movies_origin, users_origin), open('preprocess_movies.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BdmQIqbJ4XiH",
        "outputId": "c750401b-b8f7-4737-b1c9-213ca3ee45f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   UserID  Gender  Age  JobID\n",
              "0       1       0    0     10\n",
              "1       2       1    5     16\n",
              "2       3       1    6     15\n",
              "3       4       1    2      7\n",
              "4       5       1    6     20"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85ec4c84-1b93-4ac9-8670-88c7cbfd6ed2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>JobID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85ec4c84-1b93-4ac9-8670-88c7cbfd6ed2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85ec4c84-1b93-4ac9-8670-88c7cbfd6ed2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85ec4c84-1b93-4ac9-8670-88c7cbfd6ed2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "users.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QsTxAP9C4XiI",
        "outputId": "265d265f-9035-4e2c-d65a-1ef029fc229d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   MovieID                                              Title  \\\n",
              "0        1  [538, 4030, 4500, 4500, 4500, 4500, 4500, 4500...   \n",
              "1        2  [992, 4500, 4500, 4500, 4500, 4500, 4500, 4500...   \n",
              "2        3  [3179, 294, 4234, 4500, 4500, 4500, 4500, 4500...   \n",
              "3        4  [4259, 5115, 2380, 4500, 4500, 4500, 4500, 450...   \n",
              "4        5  [1987, 2306, 2707, 3855, 882, 64, 4500, 4500, ...   \n",
              "\n",
              "                                              Genres  \n",
              "0  [10, 6, 13, 12, 12, 12, 12, 12, 12, 12, 12, 12...  \n",
              "1  [14, 6, 1, 12, 12, 12, 12, 12, 12, 12, 12, 12,...  \n",
              "2  [13, 2, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12...  \n",
              "3  [13, 15, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1...  \n",
              "4  [13, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8eeb7b9-fb47-4e15-bc70-768fc92fd804\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MovieID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[538, 4030, 4500, 4500, 4500, 4500, 4500, 4500...</td>\n",
              "      <td>[10, 6, 13, 12, 12, 12, 12, 12, 12, 12, 12, 12...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[992, 4500, 4500, 4500, 4500, 4500, 4500, 4500...</td>\n",
              "      <td>[14, 6, 1, 12, 12, 12, 12, 12, 12, 12, 12, 12,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[3179, 294, 4234, 4500, 4500, 4500, 4500, 4500...</td>\n",
              "      <td>[13, 2, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[4259, 5115, 2380, 4500, 4500, 4500, 4500, 450...</td>\n",
              "      <td>[13, 15, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>[1987, 2306, 2707, 3855, 882, 64, 4500, 4500, ...</td>\n",
              "      <td>[13, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8eeb7b9-fb47-4e15-bc70-768fc92fd804')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8eeb7b9-fb47-4e15-bc70-768fc92fd804 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8eeb7b9-fb47-4e15-bc70-768fc92fd804');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "movies.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh_yU5gq4XiI"
      },
      "source": [
        "## Design Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3EeeP5i4XiJ"
      },
      "source": [
        "### Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRGzvFqh4XiJ"
      },
      "outputs": [],
      "source": [
        "def save_params(params):\n",
        "    \"\"\"Save parameters to file\"\"\"\n",
        "    pickle.dump(params, open('params.pkl', 'wb'))\n",
        "\n",
        "\n",
        "def load_params():\n",
        "    \"\"\"Load parameters from file\"\"\"\n",
        "    return pickle.load(open('params.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzuhatsB4XiJ"
      },
      "outputs": [],
      "source": [
        "# Dimension of matrix\n",
        "embed_dim = 32\n",
        "# Number of users' ids\n",
        "uid_max = max(features.take(0,1)) + 1 # 6040\n",
        "# Number of genders\n",
        "gender_max = max(features.take(2,1)) + 1 # 1 + 1 = 2\n",
        "# Number of ages\n",
        "age_max = max(features.take(3,1)) + 1 # 6 + 1 = 7\n",
        "# Number of jobs\n",
        "job_max = max(features.take(4,1)) + 1# 20 + 1 = 21\n",
        "\n",
        "# Number of movies\n",
        "movie_id_max = max(features.take(1,1)) + 1 # 3952\n",
        "# Number of genres\n",
        "movie_categories_max = max(genres2int.values()) + 1 # 18 + 1 = 19\n",
        "# Number of words of movies' names\n",
        "movie_title_max = len(title_set) # 5216\n",
        "\n",
        "combiner = \"sum\"\n",
        "\n",
        "# Length of movies' name\n",
        "sentences_size = title_count # = 15\n",
        "\n",
        "window_sizes = {2, 3, 4, 5}\n",
        "filter_num = 8\n",
        "movieid2idx = {val[0]:idx for idx, val in enumerate(movies.values)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHR-5lS34XiK"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiY3iGez4XiK"
      },
      "outputs": [],
      "source": [
        "# Number of Epochs\n",
        "num_epochs = 5\n",
        "# Batch Size\n",
        "batch_size = 256\n",
        "\n",
        "dropout_keep = 0.5\n",
        "# Learning Rate\n",
        "learning_rate = 0.0001\n",
        "# Show stats for every n number of batches\n",
        "show_every_n_batches = 20\n",
        "\n",
        "save_dir = './save'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwFJ3N1a4XiK"
      },
      "source": [
        "### Model's Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jp4ByLto4XiL"
      },
      "outputs": [],
      "source": [
        "def get_inputs():\n",
        "    uid = tf.keras.layers.Input(shape=(1,), dtype='int32', name='uid')  \n",
        "    user_gender = tf.keras.layers.Input(shape=(1,), dtype='int32', name='user_gender')  \n",
        "    user_age = tf.keras.layers.Input(shape=(1,), dtype='int32', name='user_age') \n",
        "    user_job = tf.keras.layers.Input(shape=(1,), dtype='int32', name='user_job')\n",
        "\n",
        "    movie_id = tf.keras.layers.Input(shape=(1,), dtype='int32', name='movie_id') \n",
        "    movie_categories = tf.keras.layers.Input(shape=(18,), dtype='int32', name='movie_categories') \n",
        "    movie_titles = tf.keras.layers.Input(shape=(15,), dtype='int32', name='movie_titles') \n",
        "    return uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9-zwGkU4XiL"
      },
      "source": [
        "### Build Neural Network\n",
        "\n",
        "#### Define User's Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aavtQhsR4XiL"
      },
      "outputs": [],
      "source": [
        "def get_user_embedding(uid, user_gender, user_age, user_job):\n",
        "    uid_embed_layer = tf.keras.layers.Embedding(uid_max, embed_dim, input_length=1, name='uid_embed_layer')(uid)\n",
        "    gender_embed_layer = tf.keras.layers.Embedding(gender_max, embed_dim // 2, input_length=1, name='gender_embed_layer')(user_gender)\n",
        "    age_embed_layer = tf.keras.layers.Embedding(age_max, embed_dim // 2, input_length=1, name='age_embed_layer')(user_age)\n",
        "    job_embed_layer = tf.keras.layers.Embedding(job_max, embed_dim // 2, input_length=1, name='job_embed_layer')(user_job)\n",
        "    return uid_embed_layer, gender_embed_layer, age_embed_layer, job_embed_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckyg43fb4XiL"
      },
      "source": [
        "#### Define User's Feature\n",
        "\n",
        "It is based on two fully connected layers, **1x128** and **1x200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdSWRB5u4XiM"
      },
      "outputs": [],
      "source": [
        "def get_user_feature_layer(uid_embed_layer, gender_embed_layer, age_embed_layer, job_embed_layer):\n",
        "    # First FCL\n",
        "    uid_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"uid_fc_layer\", activation='relu')(uid_embed_layer)\n",
        "    gender_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"gender_fc_layer\", activation='relu')(gender_embed_layer)\n",
        "    age_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"age_fc_layer\", activation='relu')(age_embed_layer)\n",
        "    job_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"job_fc_layer\", activation='relu')(job_embed_layer)\n",
        "\n",
        "    # Second FCL\n",
        "    user_combine_layer = tf.keras.layers.concatenate([uid_fc_layer, gender_fc_layer, age_fc_layer, job_fc_layer], 2)  #(?, 1, 128)\n",
        "    user_combine_layer = tf.keras.layers.Dense(200, activation='tanh')(user_combine_layer)  #(?, 1, 200)\n",
        "\n",
        "    user_combine_layer_flat = tf.keras.layers.Reshape([200], name=\"user_combine_layer_flat\")(user_combine_layer)\n",
        "    return user_combine_layer, user_combine_layer_flat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXBsvrKU4XiM"
      },
      "source": [
        "#### Define Movie's ID Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzYjGs8F4XiM"
      },
      "outputs": [],
      "source": [
        "def get_movie_id_embed_layer(movie_id):\n",
        "    movie_id_embed_layer = tf.keras.layers.Embedding(movie_id_max, embed_dim, input_length=1, name='movie_id_embed_layer')(movie_id)\n",
        "    return movie_id_embed_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "086A--9R4XiM"
      },
      "source": [
        "#### Define Movie's Genre Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8930dXj4XiN"
      },
      "outputs": [],
      "source": [
        "def get_movie_categories_layers(movie_categories):\n",
        "    movie_categories_embed_layer = tf.keras.layers.Embedding(movie_categories_max, embed_dim, input_length=18, name='movie_categories_embed_layer')(movie_categories)\n",
        "    movie_categories_embed_layer = tf.keras.layers.Lambda(lambda layer: tf.reduce_sum(layer, axis=1, keepdims=True))(movie_categories_embed_layer)\n",
        "    return movie_categories_embed_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BYqkT5O4XiN"
      },
      "source": [
        "#### Define CNN of Movie's Title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5BPkYyw4XiN"
      },
      "outputs": [],
      "source": [
        "def get_movie_cnn_layer(movie_titles):\n",
        "    movie_title_embed_layer = tf.keras.layers.Embedding(movie_title_max, embed_dim, input_length=15, name='movie_title_embed_layer')(movie_titles)\n",
        "    sp = movie_title_embed_layer.shape\n",
        "    movie_title_embed_layer_expand = tf.keras.layers.Reshape([sp[1], sp[2], 1])(movie_title_embed_layer)\n",
        "    pool_layer_lst = []\n",
        "    for window_size in window_sizes:\n",
        "        conv_layer = tf.keras.layers.Conv2D(filter_num, (window_size, embed_dim), 1, activation='relu')(movie_title_embed_layer_expand)\n",
        "        maxpool_layer = tf.keras.layers.MaxPooling2D(pool_size=(sentences_size - window_size + 1 ,1), strides=1)(conv_layer)\n",
        "        pool_layer_lst.append(maxpool_layer)\n",
        "    pool_layer = tf.keras.layers.concatenate(pool_layer_lst, 3, name =\"pool_layer\")  \n",
        "    max_num = len(window_sizes) * filter_num\n",
        "    pool_layer_flat = tf.keras.layers.Reshape([1, max_num], name = \"pool_layer_flat\")(pool_layer)\n",
        "\n",
        "    dropout_layer = tf.keras.layers.Dropout(dropout_keep, name = \"dropout_layer\")(pool_layer_flat)\n",
        "    return pool_layer_flat, dropout_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHwe5gQE4XiO"
      },
      "source": [
        "#### Define Movie's Feature\n",
        "\n",
        "It is based on two fully connected layers, **1x64** and **1x200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1u_3pbK4XiO"
      },
      "outputs": [],
      "source": [
        "def get_movie_feature_layer(movie_id_embed_layer, movie_categories_embed_layer, dropout_layer):\n",
        "    # First FCL 64\n",
        "    movie_id_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"movie_id_fc_layer\", activation='relu')(movie_id_embed_layer)\n",
        "    movie_categories_fc_layer = tf.keras.layers.Dense(embed_dim, name=\"movie_categories_fc_layer\", activation='relu')(movie_categories_embed_layer)\n",
        "\n",
        "    # Second FCL 200\n",
        "    movie_combine_layer = tf.keras.layers.concatenate([movie_id_fc_layer, movie_categories_fc_layer, dropout_layer], 2)  \n",
        "    movie_combine_layer = tf.keras.layers.Dense(200, activation='tanh')(movie_combine_layer)\n",
        "\n",
        "    movie_combine_layer_flat = tf.keras.layers.Reshape([200], name=\"movie_combine_layer_flat\")(movie_combine_layer)\n",
        "    return movie_combine_layer, movie_combine_layer_flat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNg9_A_B4XiO",
        "outputId": "70bd659d-01c1-4db2-de18-7e9534388537"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'keras.api._v2.keras.layers' from '/usr/local/lib/python3.7/dist-packages/keras/api/_v2/keras/layers/__init__.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "tf.keras.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWhqMY_W4XiO"
      },
      "source": [
        "### Build Computing Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBBw_FiM4XiP"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.ops import summary_ops_v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rAWyLdL4XiP"
      },
      "outputs": [],
      "source": [
        "MODEL_DIR = \"./models\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyAYKhnk4XiP"
      },
      "outputs": [],
      "source": [
        "class mrs_network():\n",
        "    def __init__(self, batch_size=256):\n",
        "        self.batch_size = batch_size\n",
        "        self.best_rmse = 99999\n",
        "        self.losses = {'train': [], 'test': []}\n",
        "        \n",
        "        # User's input\n",
        "        uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles = get_inputs()\n",
        "        \n",
        "        # User's embedding layers\n",
        "        uid_embed_layer, gender_embed_layer, age_embed_layer, job_embed_layer = get_user_embedding(uid, \n",
        "                                                                                                   user_gender,\n",
        "                                                                                                   user_age,\n",
        "                                                                                                   user_job)\n",
        "        # User's feature\n",
        "        user_combine_layer, user_combine_layer_flat = get_user_feature_layer(uid_embed_layer, \n",
        "                                                                             gender_embed_layer, \n",
        "                                                                             age_embed_layer, \n",
        "                                                                             job_embed_layer)\n",
        "        \n",
        "        # Movie's id embedding layer\n",
        "        movie_id_embed_layer = get_movie_id_embed_layer(movie_id)\n",
        "        # Movie's genre embedding layer\n",
        "        movie_categories_embed_layer = get_movie_categories_layers(movie_categories)\n",
        "        # Movie's name layer\n",
        "        pool_layer_flat, dropout_layer = get_movie_cnn_layer(movie_titles)\n",
        "        # Movie's feature\n",
        "        movie_combine_layer, movie_combine_layer_flat = get_movie_feature_layer(movie_id_embed_layer,\n",
        "                                                                                movie_categories_embed_layer,\n",
        "                                                                                dropout_layer)\n",
        "        # Combine user's feature and movie's feature to get rating prediction\n",
        "        inference = tf.keras.layers.Lambda(lambda layer: \n",
        "            tf.reduce_sum(layer[0] * layer[1], axis=1), name=\"inference\")((user_combine_layer_flat, movie_combine_layer_flat))\n",
        "        inference = tf.keras.layers.Lambda(lambda layer: tf.expand_dims(layer, axis=1))(inference)\n",
        "        \n",
        "        self.model = tf.keras.Model(\n",
        "            inputs=[uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles],\n",
        "            outputs=[inference])\n",
        "\n",
        "        self.model.summary()\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "        # MSE Loss\n",
        "        self.ComputeLoss = tf.keras.losses.MeanSquaredError()\n",
        "        self.ComputeMetrics = tf.keras.metrics.RootMeanSquaredError()\n",
        "        \n",
        "        if tf.io.gfile.exists(MODEL_DIR):\n",
        "            pass\n",
        "        else:\n",
        "            tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "        train_dir = os.path.join(MODEL_DIR, 'summaries', 'train')\n",
        "        test_dir = os.path.join(MODEL_DIR, 'summaries', 'eval')\n",
        "\n",
        "        checkpoint_dir = os.path.join(MODEL_DIR, 'checkpoints')\n",
        "        self.checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "        self.checkpoint = tf.train.Checkpoint(model=self.model, optimizer=self.optimizer)\n",
        "\n",
        "        # Restore variables on creation if a checkpoint exists.\n",
        "        self.checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "    def compute_loss(self, labels, logits):\n",
        "        return tf.reduce_mean(tf.keras.losses.mse(labels, logits))\n",
        "\n",
        "    def compute_metrics(self, labels, logits):\n",
        "        return tf.keras.metrics.rmse(labels, logits)\n",
        "        \n",
        "    @tf.function\n",
        "    def train_step(self, x, y):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = self.model([x[0],\n",
        "                                 x[1],\n",
        "                                 x[2],\n",
        "                                 x[3],\n",
        "                                 x[4],\n",
        "                                 x[5],\n",
        "                                 x[6]], training=True)\n",
        "            loss = self.ComputeLoss(y, logits)\n",
        "            self.ComputeMetrics(y, logits)\n",
        "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
        "        return loss, logits\n",
        "    \n",
        "    def training(self, features, targets_values, epochs=5, log_freq=50):\n",
        "        for epoch_i in range(epochs):\n",
        "            # separate the dataset into training and testing\n",
        "            train_X, test_X, train_y, test_y = train_test_split(features,\n",
        "                                                                targets_values,\n",
        "                                                                test_size=0.2,\n",
        "                                                                random_state=0)\n",
        "\n",
        "            train_batches = get_batches(train_X, train_y, self.batch_size)\n",
        "            batch_num = (len(train_X) // self.batch_size)\n",
        "            train_start = time.time()\n",
        "            \n",
        "            if True:\n",
        "                start = time.time()\n",
        "                avg_loss = tf.keras.metrics.Mean('loss', dtype=tf.float32)\n",
        "\n",
        "                for batch_i in range(batch_num):\n",
        "                    x, y = next(train_batches)\n",
        "                    categories = np.zeros([self.batch_size, 18])\n",
        "                    for i in range(self.batch_size):\n",
        "                        categories[i] = x.take(6, 1)[i]\n",
        "\n",
        "                    titles = np.zeros([self.batch_size, sentences_size])\n",
        "                    for i in range(self.batch_size):\n",
        "                        titles[i] = x.take(5, 1)[i]\n",
        "\n",
        "                    loss, logits = self.train_step([np.reshape(x.take(0, 1), [self.batch_size, 1]).astype(np.float32),\n",
        "                                                    np.reshape(x.take(2, 1), [self.batch_size, 1]).astype(np.float32),\n",
        "                                                    np.reshape(x.take(3, 1), [self.batch_size, 1]).astype(np.float32),\n",
        "                                                    np.reshape(x.take(4, 1), [self.batch_size, 1]).astype(np.float32),\n",
        "                                                    np.reshape(x.take(1, 1), [self.batch_size, 1]).astype(np.float32),\n",
        "                                                    categories.astype(np.float32),\n",
        "                                                    titles.astype(np.float32)],\n",
        "                                                   np.reshape(y, [self.batch_size, 1]).astype(np.float32))\n",
        "                    avg_loss(loss)\n",
        "                    self.losses['train'].append(loss)\n",
        "\n",
        "                    if tf.equal(self.optimizer.iterations % log_freq, 0):\n",
        "                        rate = log_freq / (time.time() - start)\n",
        "                        print('Step #{}\\tEpoch {:>3} Batch {:>4}/{}   Loss: {:0.6f} rmse: {:0.6f} ({} steps/sec)'.format(\n",
        "                            self.optimizer.iterations.numpy(),\n",
        "                            epoch_i,\n",
        "                            batch_i,\n",
        "                            batch_num,\n",
        "                            loss, (self.ComputeMetrics.result()), rate))\n",
        "                        avg_loss.reset_states()\n",
        "                        self.ComputeMetrics.reset_states()\n",
        "                        start = time.time()\n",
        "\n",
        "            train_end = time.time()\n",
        "            print('\\nTrain time for epoch #{} ({} total steps): {}'.format(epoch_i + 1, \n",
        "                                                                           self.optimizer.iterations.numpy(),\n",
        "                                                                           train_end - train_start))\n",
        "            self.testing((test_X, test_y), self.optimizer.iterations)\n",
        "        self.export_path = os.path.join(MODEL_DIR, 'export')\n",
        "        tf.saved_model.save(self.model, self.export_path)\n",
        "    \n",
        "    def testing(self, test_dataset, step_num):\n",
        "        test_X, test_y = test_dataset\n",
        "        test_batches = get_batches(test_X, test_y, self.batch_size)\n",
        "\n",
        "        avg_loss = tf.keras.metrics.Mean('loss', dtype=tf.float32)\n",
        "\n",
        "        batch_num = (len(test_X) // self.batch_size)\n",
        "        for batch_i in range(batch_num):\n",
        "            x, y = next(test_batches)\n",
        "            categories = np.zeros([self.batch_size, 18])\n",
        "            for i in range(self.batch_size):\n",
        "                categories[i] = x.take(6, 1)[i]\n",
        "\n",
        "            titles = np.zeros([self.batch_size, sentences_size])\n",
        "            for i in range(self.batch_size):\n",
        "                titles[i] = x.take(5, 1)[i]\n",
        "\n",
        "            logits = self.model([np.reshape(x.take(0, 1), [self.batch_size, 1]).astype(np.float32),\n",
        "                                 np.reshape(x.take(2, 1), [self.batch_size, 1]).astype(np.float32),\n",
        "                                 np.reshape(x.take(3, 1), [self.batch_size, 1]).astype(np.float32),\n",
        "                                 np.reshape(x.take(4, 1), [self.batch_size, 1]).astype(np.float32),\n",
        "                                 np.reshape(x.take(1, 1), [self.batch_size, 1]).astype(np.float32),\n",
        "                                 categories.astype(np.float32),\n",
        "                                 titles.astype(np.float32)], training=False)\n",
        "            test_loss = self.ComputeLoss(np.reshape(y, [self.batch_size, 1]).astype(np.float32), logits)\n",
        "            avg_loss(test_loss)\n",
        "            # Save testing loss\n",
        "            self.losses['test'].append(test_loss)\n",
        "            self.ComputeMetrics(np.reshape(y, [self.batch_size, 1]).astype(np.float32), logits)\n",
        "\n",
        "        print('Model test set loss: {:0.6f} rmse: {:0.6f}'.format(avg_loss.result(), \n",
        "                                                                 self.ComputeMetrics.result()))\n",
        "        if(self.ComputeMetrics.result() < self.best_rmse):\n",
        "          self.best_rmse = self.ComputeMetrics.result()\n",
        "          print(f'best rmse = { self.best_rmse }')\n",
        "          self.checkpoint.save(self.checkpoint_prefix)\n",
        "\n",
        "    \n",
        "    def forward(self, xs):\n",
        "        predictions = self.model(xs)\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a8s62aj4XiQ"
      },
      "source": [
        "### Get Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exiLP1QS4XiQ"
      },
      "outputs": [],
      "source": [
        "def get_batches(Xs, ys, batch_size):\n",
        "    for start in range(0, len(Xs), batch_size):\n",
        "        end = min(start + batch_size, len(Xs))\n",
        "        yield Xs[start:end], ys[start:end]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82jopldE4XiQ"
      },
      "source": [
        "### Train Network\n",
        "\n",
        "Input the user's feature and movie's feature, output the training result through the fully connected layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBtDPeFz4XiR",
        "outputId": "7a8d851f-77a1-4440-c2b7-744486c1c826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " movie_titles (InputLayer)      [(None, 15)]         0           []                               \n",
            "                                                                                                  \n",
            " movie_title_embed_layer (Embed  (None, 15, 32)      166944      ['movie_titles[0][0]']           \n",
            " ding)                                                                                            \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 15, 32, 1)    0           ['movie_title_embed_layer[0][0]']\n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 14, 1, 8)     520         ['reshape[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 13, 1, 8)     776         ['reshape[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 12, 1, 8)     1032        ['reshape[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 11, 1, 8)     1288        ['reshape[0][0]']                \n",
            "                                                                                                  \n",
            " movie_categories (InputLayer)  [(None, 18)]         0           []                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 1, 1, 8)      0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 8)     0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 8)     0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 8)     0           ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " uid (InputLayer)               [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " user_gender (InputLayer)       [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " user_age (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " user_job (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " movie_id (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " movie_categories_embed_layer (  (None, 18, 32)      608         ['movie_categories[0][0]']       \n",
            " Embedding)                                                                                       \n",
            "                                                                                                  \n",
            " pool_layer (Concatenate)       (None, 1, 1, 32)     0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'max_pooling2d_1[0][0]',        \n",
            "                                                                  'max_pooling2d_2[0][0]',        \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " uid_embed_layer (Embedding)    (None, 1, 32)        193312      ['uid[0][0]']                    \n",
            "                                                                                                  \n",
            " gender_embed_layer (Embedding)  (None, 1, 16)       32          ['user_gender[0][0]']            \n",
            "                                                                                                  \n",
            " age_embed_layer (Embedding)    (None, 1, 16)        112         ['user_age[0][0]']               \n",
            "                                                                                                  \n",
            " job_embed_layer (Embedding)    (None, 1, 16)        336         ['user_job[0][0]']               \n",
            "                                                                                                  \n",
            " movie_id_embed_layer (Embeddin  (None, 1, 32)       126496      ['movie_id[0][0]']               \n",
            " g)                                                                                               \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 1, 32)        0           ['movie_categories_embed_layer[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " pool_layer_flat (Reshape)      (None, 1, 32)        0           ['pool_layer[0][0]']             \n",
            "                                                                                                  \n",
            " uid_fc_layer (Dense)           (None, 1, 32)        1056        ['uid_embed_layer[0][0]']        \n",
            "                                                                                                  \n",
            " gender_fc_layer (Dense)        (None, 1, 32)        544         ['gender_embed_layer[0][0]']     \n",
            "                                                                                                  \n",
            " age_fc_layer (Dense)           (None, 1, 32)        544         ['age_embed_layer[0][0]']        \n",
            "                                                                                                  \n",
            " job_fc_layer (Dense)           (None, 1, 32)        544         ['job_embed_layer[0][0]']        \n",
            "                                                                                                  \n",
            " movie_id_fc_layer (Dense)      (None, 1, 32)        1056        ['movie_id_embed_layer[0][0]']   \n",
            "                                                                                                  \n",
            " movie_categories_fc_layer (Den  (None, 1, 32)       1056        ['lambda[0][0]']                 \n",
            " se)                                                                                              \n",
            "                                                                                                  \n",
            " dropout_layer (Dropout)        (None, 1, 32)        0           ['pool_layer_flat[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 1, 128)       0           ['uid_fc_layer[0][0]',           \n",
            "                                                                  'gender_fc_layer[0][0]',        \n",
            "                                                                  'age_fc_layer[0][0]',           \n",
            "                                                                  'job_fc_layer[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 1, 96)        0           ['movie_id_fc_layer[0][0]',      \n",
            "                                                                  'movie_categories_fc_layer[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'dropout_layer[0][0]']          \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1, 200)       25800       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1, 200)       19400       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " user_combine_layer_flat (Resha  (None, 200)         0           ['dense[0][0]']                  \n",
            " pe)                                                                                              \n",
            "                                                                                                  \n",
            " movie_combine_layer_flat (Resh  (None, 200)         0           ['dense_1[0][0]']                \n",
            " ape)                                                                                             \n",
            "                                                                                                  \n",
            " inference (Lambda)             (None,)              0           ['user_combine_layer_flat[0][0]',\n",
            "                                                                  'movie_combine_layer_flat[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 1)            0           ['inference[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 541,456\n",
            "Trainable params: 541,456\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Step #50\tEpoch   0 Batch   49/3125   Loss: 9.052917 rmse: 3.448035 (11.210372707987055 steps/sec)\n",
            "Step #100\tEpoch   0 Batch   99/3125   Loss: 1.535793 rmse: 2.069761 (29.200359401548802 steps/sec)\n",
            "Step #150\tEpoch   0 Batch  149/3125   Loss: 1.264179 rmse: 1.159980 (28.65700097046862 steps/sec)\n",
            "Step #200\tEpoch   0 Batch  199/3125   Loss: 1.236535 rmse: 1.125764 (29.019866581942733 steps/sec)\n",
            "Step #250\tEpoch   0 Batch  249/3125   Loss: 1.121377 rmse: 1.109122 (28.878531132573283 steps/sec)\n",
            "Step #300\tEpoch   0 Batch  299/3125   Loss: 1.335204 rmse: 1.104359 (29.08866155666184 steps/sec)\n",
            "Step #350\tEpoch   0 Batch  349/3125   Loss: 1.185231 rmse: 1.094116 (28.685470405565646 steps/sec)\n",
            "Step #400\tEpoch   0 Batch  399/3125   Loss: 1.294976 rmse: 1.088490 (29.0467403941483 steps/sec)\n",
            "Step #450\tEpoch   0 Batch  449/3125   Loss: 1.099063 rmse: 1.080973 (29.154986517664945 steps/sec)\n",
            "Step #500\tEpoch   0 Batch  499/3125   Loss: 1.029099 rmse: 1.060665 (29.00965424437057 steps/sec)\n",
            "Step #550\tEpoch   0 Batch  549/3125   Loss: 1.032526 rmse: 1.050359 (28.58404599721513 steps/sec)\n",
            "Step #600\tEpoch   0 Batch  599/3125   Loss: 0.893744 rmse: 1.047019 (29.126710618840104 steps/sec)\n",
            "Step #650\tEpoch   0 Batch  649/3125   Loss: 1.038858 rmse: 1.025007 (29.38513710248518 steps/sec)\n",
            "Step #700\tEpoch   0 Batch  699/3125   Loss: 0.896515 rmse: 1.009724 (29.05381881789037 steps/sec)\n",
            "Step #750\tEpoch   0 Batch  749/3125   Loss: 0.913539 rmse: 0.988678 (29.283206872188135 steps/sec)\n",
            "Step #800\tEpoch   0 Batch  799/3125   Loss: 1.047445 rmse: 0.987008 (29.47609580372058 steps/sec)\n",
            "Step #850\tEpoch   0 Batch  849/3125   Loss: 1.040396 rmse: 0.982257 (29.087003365359543 steps/sec)\n",
            "Step #900\tEpoch   0 Batch  899/3125   Loss: 1.000937 rmse: 0.970229 (28.97631754968484 steps/sec)\n",
            "Step #950\tEpoch   0 Batch  949/3125   Loss: 0.778679 rmse: 0.962135 (29.188272704206717 steps/sec)\n",
            "Step #1000\tEpoch   0 Batch  999/3125   Loss: 0.983979 rmse: 0.962812 (29.10234582321405 steps/sec)\n",
            "Step #1050\tEpoch   0 Batch 1049/3125   Loss: 0.944496 rmse: 0.965655 (28.220439348417504 steps/sec)\n",
            "Step #1100\tEpoch   0 Batch 1099/3125   Loss: 0.873843 rmse: 0.951190 (29.4655598984952 steps/sec)\n",
            "Step #1150\tEpoch   0 Batch 1149/3125   Loss: 0.810654 rmse: 0.956386 (29.32654792955874 steps/sec)\n",
            "Step #1200\tEpoch   0 Batch 1199/3125   Loss: 0.805933 rmse: 0.935173 (29.410489345535723 steps/sec)\n",
            "Step #1250\tEpoch   0 Batch 1249/3125   Loss: 1.011930 rmse: 0.947741 (28.838057646633025 steps/sec)\n",
            "Step #1300\tEpoch   0 Batch 1299/3125   Loss: 0.880787 rmse: 0.951234 (28.851852417443524 steps/sec)\n",
            "Step #1350\tEpoch   0 Batch 1349/3125   Loss: 0.936372 rmse: 0.925314 (28.686867305155122 steps/sec)\n",
            "Step #1400\tEpoch   0 Batch 1399/3125   Loss: 0.869164 rmse: 0.937474 (29.479236496726102 steps/sec)\n",
            "Step #1450\tEpoch   0 Batch 1449/3125   Loss: 0.864182 rmse: 0.937702 (28.947999385468993 steps/sec)\n",
            "Step #1500\tEpoch   0 Batch 1499/3125   Loss: 0.867843 rmse: 0.934454 (29.470354789203867 steps/sec)\n",
            "Step #1550\tEpoch   0 Batch 1549/3125   Loss: 0.914392 rmse: 0.935283 (29.242876347853176 steps/sec)\n",
            "Step #1600\tEpoch   0 Batch 1599/3125   Loss: 0.844622 rmse: 0.925983 (29.618603032572594 steps/sec)\n",
            "Step #1650\tEpoch   0 Batch 1649/3125   Loss: 0.899242 rmse: 0.932535 (29.064126726484258 steps/sec)\n",
            "Step #1700\tEpoch   0 Batch 1699/3125   Loss: 0.901722 rmse: 0.921886 (29.25789797867272 steps/sec)\n",
            "Step #1750\tEpoch   0 Batch 1749/3125   Loss: 0.880317 rmse: 0.924896 (29.02773948294782 steps/sec)\n",
            "Step #1800\tEpoch   0 Batch 1799/3125   Loss: 1.003545 rmse: 0.930313 (29.031388172885514 steps/sec)\n",
            "Step #1850\tEpoch   0 Batch 1849/3125   Loss: 0.781603 rmse: 0.924021 (29.296186728769523 steps/sec)\n",
            "Step #1900\tEpoch   0 Batch 1899/3125   Loss: 0.878732 rmse: 0.922875 (29.0948521937413 steps/sec)\n",
            "Step #1950\tEpoch   0 Batch 1949/3125   Loss: 0.821936 rmse: 0.915543 (28.287201245679668 steps/sec)\n",
            "Step #2000\tEpoch   0 Batch 1999/3125   Loss: 0.952949 rmse: 0.928024 (29.26142103365559 steps/sec)\n",
            "Step #2050\tEpoch   0 Batch 2049/3125   Loss: 0.818104 rmse: 0.929112 (28.77634741964029 steps/sec)\n",
            "Step #2100\tEpoch   0 Batch 2099/3125   Loss: 0.871080 rmse: 0.916368 (28.528837612348813 steps/sec)\n",
            "Step #2150\tEpoch   0 Batch 2149/3125   Loss: 0.800574 rmse: 0.915001 (28.947843548867098 steps/sec)\n",
            "Step #2200\tEpoch   0 Batch 2199/3125   Loss: 0.770837 rmse: 0.918292 (28.961251631973223 steps/sec)\n",
            "Step #2250\tEpoch   0 Batch 2249/3125   Loss: 0.822796 rmse: 0.916477 (28.112925606150238 steps/sec)\n",
            "Step #2300\tEpoch   0 Batch 2299/3125   Loss: 0.864536 rmse: 0.930061 (28.313453248385628 steps/sec)\n",
            "Step #2350\tEpoch   0 Batch 2349/3125   Loss: 0.841482 rmse: 0.921207 (28.662691902768216 steps/sec)\n",
            "Step #2400\tEpoch   0 Batch 2399/3125   Loss: 0.771058 rmse: 0.919392 (28.464725097783564 steps/sec)\n",
            "Step #2450\tEpoch   0 Batch 2449/3125   Loss: 0.841392 rmse: 0.911489 (28.752848855295905 steps/sec)\n",
            "Step #2500\tEpoch   0 Batch 2499/3125   Loss: 0.941187 rmse: 0.923361 (29.632991549486828 steps/sec)\n",
            "Step #2550\tEpoch   0 Batch 2549/3125   Loss: 0.672746 rmse: 0.924410 (19.35591291818017 steps/sec)\n",
            "Step #2600\tEpoch   0 Batch 2599/3125   Loss: 1.027410 rmse: 0.927657 (28.885830178780274 steps/sec)\n",
            "Step #2650\tEpoch   0 Batch 2649/3125   Loss: 0.914240 rmse: 0.918233 (28.7646998634153 steps/sec)\n",
            "Step #2700\tEpoch   0 Batch 2699/3125   Loss: 0.806595 rmse: 0.913477 (28.655368133304346 steps/sec)\n",
            "Step #2750\tEpoch   0 Batch 2749/3125   Loss: 1.006507 rmse: 0.910184 (29.108505924407762 steps/sec)\n",
            "Step #2800\tEpoch   0 Batch 2799/3125   Loss: 0.859418 rmse: 0.921267 (28.405889521424573 steps/sec)\n",
            "Step #2850\tEpoch   0 Batch 2849/3125   Loss: 0.857380 rmse: 0.915688 (27.88160867216051 steps/sec)\n",
            "Step #2900\tEpoch   0 Batch 2899/3125   Loss: 0.866640 rmse: 0.909777 (28.9062672294779 steps/sec)\n",
            "Step #2950\tEpoch   0 Batch 2949/3125   Loss: 0.887929 rmse: 0.915071 (28.67818989602619 steps/sec)\n",
            "Step #3000\tEpoch   0 Batch 2999/3125   Loss: 0.755713 rmse: 0.912371 (28.211609130320788 steps/sec)\n",
            "Step #3050\tEpoch   0 Batch 3049/3125   Loss: 0.800189 rmse: 0.903963 (17.683174544819845 steps/sec)\n",
            "Step #3100\tEpoch   0 Batch 3099/3125   Loss: 0.903105 rmse: 0.911499 (28.17568097713757 steps/sec)\n",
            "\n",
            "Train time for epoch #1 (3125 total steps): 112.91741633415222\n",
            "Model test set loss: 0.841918 rmse: 0.917361\n",
            "best rmse = 0.917360782623291\n",
            "Step #3150\tEpoch   1 Batch   24/3125   Loss: 0.739069 rmse: 0.917247 (53.49535017018043 steps/sec)\n",
            "Step #3200\tEpoch   1 Batch   74/3125   Loss: 0.883492 rmse: 0.906833 (29.084155429328405 steps/sec)\n",
            "Step #3250\tEpoch   1 Batch  124/3125   Loss: 0.719538 rmse: 0.916970 (29.12869700683704 steps/sec)\n",
            "Step #3300\tEpoch   1 Batch  174/3125   Loss: 0.759762 rmse: 0.911535 (29.185051545387466 steps/sec)\n",
            "Step #3350\tEpoch   1 Batch  224/3125   Loss: 0.608622 rmse: 0.914039 (28.94910627320454 steps/sec)\n",
            "Step #3400\tEpoch   1 Batch  274/3125   Loss: 0.838196 rmse: 0.911124 (28.634338015807412 steps/sec)\n",
            "Step #3450\tEpoch   1 Batch  324/3125   Loss: 0.827379 rmse: 0.915852 (28.737081069555824 steps/sec)\n",
            "Step #3500\tEpoch   1 Batch  374/3125   Loss: 0.816216 rmse: 0.917378 (29.121937922416283 steps/sec)\n",
            "Step #3550\tEpoch   1 Batch  424/3125   Loss: 0.882808 rmse: 0.916570 (29.244695094205856 steps/sec)\n",
            "Step #3600\tEpoch   1 Batch  474/3125   Loss: 0.796285 rmse: 0.908837 (28.706642525815283 steps/sec)\n",
            "Step #3650\tEpoch   1 Batch  524/3125   Loss: 0.833917 rmse: 0.905832 (28.77512341053664 steps/sec)\n",
            "Step #3700\tEpoch   1 Batch  574/3125   Loss: 0.906222 rmse: 0.918578 (28.885854050923296 steps/sec)\n",
            "Step #3750\tEpoch   1 Batch  624/3125   Loss: 0.652169 rmse: 0.912150 (28.602302557149656 steps/sec)\n",
            "Step #3800\tEpoch   1 Batch  674/3125   Loss: 0.840306 rmse: 0.913791 (28.83358124932888 steps/sec)\n",
            "Step #3850\tEpoch   1 Batch  724/3125   Loss: 0.669596 rmse: 0.908556 (28.41334807595149 steps/sec)\n",
            "Step #3900\tEpoch   1 Batch  774/3125   Loss: 0.768335 rmse: 0.900136 (28.508349268712568 steps/sec)\n",
            "Step #3950\tEpoch   1 Batch  824/3125   Loss: 0.852152 rmse: 0.910373 (28.868481592136227 steps/sec)\n",
            "Step #4000\tEpoch   1 Batch  874/3125   Loss: 0.788005 rmse: 0.911338 (28.453544577109486 steps/sec)\n",
            "Step #4050\tEpoch   1 Batch  924/3125   Loss: 0.933161 rmse: 0.916379 (28.347518906776134 steps/sec)\n",
            "Step #4100\tEpoch   1 Batch  974/3125   Loss: 0.762093 rmse: 0.912106 (28.322500345733648 steps/sec)\n",
            "Step #4150\tEpoch   1 Batch 1024/3125   Loss: 0.830888 rmse: 0.911447 (28.93490697280716 steps/sec)\n",
            "Step #4200\tEpoch   1 Batch 1074/3125   Loss: 0.860355 rmse: 0.909273 (28.847018580287592 steps/sec)\n",
            "Step #4250\tEpoch   1 Batch 1124/3125   Loss: 0.839836 rmse: 0.916018 (28.965747757976054 steps/sec)\n",
            "Step #4300\tEpoch   1 Batch 1174/3125   Loss: 0.768285 rmse: 0.912196 (28.61579455539709 steps/sec)\n",
            "Step #4350\tEpoch   1 Batch 1224/3125   Loss: 0.771026 rmse: 0.906224 (28.857982369147066 steps/sec)\n",
            "Step #4400\tEpoch   1 Batch 1274/3125   Loss: 0.955433 rmse: 0.927759 (29.29141152023 steps/sec)\n",
            "Step #4450\tEpoch   1 Batch 1324/3125   Loss: 0.781678 rmse: 0.906865 (29.206020098468823 steps/sec)\n",
            "Step #4500\tEpoch   1 Batch 1374/3125   Loss: 0.793417 rmse: 0.902902 (28.925759701323525 steps/sec)\n",
            "Step #4550\tEpoch   1 Batch 1424/3125   Loss: 0.842935 rmse: 0.909320 (28.70282750946769 steps/sec)\n",
            "Step #4600\tEpoch   1 Batch 1474/3125   Loss: 0.729697 rmse: 0.910659 (28.89531450345961 steps/sec)\n",
            "Step #4650\tEpoch   1 Batch 1524/3125   Loss: 0.739201 rmse: 0.903888 (28.06332404112551 steps/sec)\n",
            "Step #4700\tEpoch   1 Batch 1574/3125   Loss: 0.793159 rmse: 0.917925 (28.832566422489805 steps/sec)\n",
            "Step #4750\tEpoch   1 Batch 1624/3125   Loss: 0.902751 rmse: 0.898420 (28.964919629900184 steps/sec)\n",
            "Step #4800\tEpoch   1 Batch 1674/3125   Loss: 0.781689 rmse: 0.909945 (28.333539818573108 steps/sec)\n",
            "Step #4850\tEpoch   1 Batch 1724/3125   Loss: 0.919123 rmse: 0.909243 (29.23270206703575 steps/sec)\n",
            "Step #4900\tEpoch   1 Batch 1774/3125   Loss: 0.758979 rmse: 0.903264 (28.430882241096743 steps/sec)\n",
            "Step #4950\tEpoch   1 Batch 1824/3125   Loss: 0.735505 rmse: 0.911222 (29.604495943405162 steps/sec)\n",
            "Step #5000\tEpoch   1 Batch 1874/3125   Loss: 0.899636 rmse: 0.907118 (29.15914161820255 steps/sec)\n",
            "Step #5050\tEpoch   1 Batch 1924/3125   Loss: 1.013939 rmse: 0.904179 (28.7140829561888 steps/sec)\n",
            "Step #5100\tEpoch   1 Batch 1974/3125   Loss: 0.820186 rmse: 0.900910 (28.7846023284328 steps/sec)\n",
            "Step #5150\tEpoch   1 Batch 2024/3125   Loss: 0.868130 rmse: 0.913134 (28.650642960171524 steps/sec)\n",
            "Step #5200\tEpoch   1 Batch 2074/3125   Loss: 0.891600 rmse: 0.903442 (28.45462941718641 steps/sec)\n",
            "Step #5250\tEpoch   1 Batch 2124/3125   Loss: 0.657658 rmse: 0.911484 (29.0647631573659 steps/sec)\n",
            "Step #5300\tEpoch   1 Batch 2174/3125   Loss: 0.740888 rmse: 0.895993 (29.05684198158564 steps/sec)\n",
            "Step #5350\tEpoch   1 Batch 2224/3125   Loss: 0.720215 rmse: 0.907776 (28.407020752960406 steps/sec)\n",
            "Step #5400\tEpoch   1 Batch 2274/3125   Loss: 0.861807 rmse: 0.908019 (28.70012892909748 steps/sec)\n",
            "Step #5450\tEpoch   1 Batch 2324/3125   Loss: 0.684412 rmse: 0.913543 (28.909255777779066 steps/sec)\n",
            "Step #5500\tEpoch   1 Batch 2374/3125   Loss: 0.775424 rmse: 0.902884 (28.149683718205715 steps/sec)\n",
            "Step #5550\tEpoch   1 Batch 2424/3125   Loss: 0.775782 rmse: 0.904026 (28.60624697691942 steps/sec)\n",
            "Step #5600\tEpoch   1 Batch 2474/3125   Loss: 0.879437 rmse: 0.900125 (28.918177280261222 steps/sec)\n",
            "Step #5650\tEpoch   1 Batch 2524/3125   Loss: 0.783960 rmse: 0.910157 (28.75939823846711 steps/sec)\n",
            "Step #5700\tEpoch   1 Batch 2574/3125   Loss: 0.886764 rmse: 0.913730 (28.982780887676714 steps/sec)\n",
            "Step #5750\tEpoch   1 Batch 2624/3125   Loss: 0.968337 rmse: 0.915060 (28.648517727666466 steps/sec)\n",
            "Step #5800\tEpoch   1 Batch 2674/3125   Loss: 0.829053 rmse: 0.902486 (28.57570712254765 steps/sec)\n",
            "Step #5850\tEpoch   1 Batch 2724/3125   Loss: 0.795766 rmse: 0.893428 (28.93341396023648 steps/sec)\n",
            "Step #5900\tEpoch   1 Batch 2774/3125   Loss: 0.769588 rmse: 0.906134 (29.331330499715378 steps/sec)\n",
            "Step #5950\tEpoch   1 Batch 2824/3125   Loss: 0.840454 rmse: 0.915491 (23.891283287020034 steps/sec)\n",
            "Step #6000\tEpoch   1 Batch 2874/3125   Loss: 0.860919 rmse: 0.897268 (20.407356586432417 steps/sec)\n",
            "Step #6050\tEpoch   1 Batch 2924/3125   Loss: 0.839275 rmse: 0.899911 (28.1649192341846 steps/sec)\n",
            "Step #6100\tEpoch   1 Batch 2974/3125   Loss: 0.751909 rmse: 0.904228 (29.06616904335022 steps/sec)\n",
            "Step #6150\tEpoch   1 Batch 3024/3125   Loss: 0.716395 rmse: 0.898875 (28.655888898089444 steps/sec)\n",
            "Step #6200\tEpoch   1 Batch 3074/3125   Loss: 0.827467 rmse: 0.896688 (28.35212928390984 steps/sec)\n",
            "Step #6250\tEpoch   1 Batch 3124/3125   Loss: 0.862921 rmse: 0.896578 (28.4760381391029 steps/sec)\n",
            "\n",
            "Train time for epoch #2 (6250 total steps): 109.89266467094421\n",
            "Model test set loss: 0.827142 rmse: 0.909473\n",
            "best rmse = 0.9094733595848083\n",
            "Step #6300\tEpoch   2 Batch   49/3125   Loss: 0.901570 rmse: 0.909116 (27.885764677426838 steps/sec)\n",
            "Step #6350\tEpoch   2 Batch   99/3125   Loss: 0.996645 rmse: 0.896283 (28.913695908974095 steps/sec)\n",
            "Step #6400\tEpoch   2 Batch  149/3125   Loss: 0.786735 rmse: 0.905300 (28.49462540911349 steps/sec)\n",
            "Step #6450\tEpoch   2 Batch  199/3125   Loss: 0.860293 rmse: 0.905607 (28.451305666975355 steps/sec)\n",
            "Step #6500\tEpoch   2 Batch  249/3125   Loss: 0.835698 rmse: 0.899784 (28.822972704410432 steps/sec)\n",
            "Step #6550\tEpoch   2 Batch  299/3125   Loss: 0.777544 rmse: 0.907564 (28.914138402513817 steps/sec)\n",
            "Step #6600\tEpoch   2 Batch  349/3125   Loss: 0.883282 rmse: 0.909000 (28.641701890310916 steps/sec)\n",
            "Step #6650\tEpoch   2 Batch  399/3125   Loss: 0.916175 rmse: 0.902563 (28.981286935679748 steps/sec)\n",
            "Step #6700\tEpoch   2 Batch  449/3125   Loss: 0.800355 rmse: 0.911603 (28.51598581129986 steps/sec)\n",
            "Step #6750\tEpoch   2 Batch  499/3125   Loss: 0.803725 rmse: 0.893215 (29.298687480406088 steps/sec)\n",
            "Step #6800\tEpoch   2 Batch  549/3125   Loss: 0.791570 rmse: 0.897995 (28.779514532875915 steps/sec)\n",
            "Step #6850\tEpoch   2 Batch  599/3125   Loss: 0.720676 rmse: 0.914918 (29.19274613533873 steps/sec)\n",
            "Step #6900\tEpoch   2 Batch  649/3125   Loss: 0.773240 rmse: 0.906135 (29.217527183775235 steps/sec)\n",
            "Step #6950\tEpoch   2 Batch  699/3125   Loss: 0.773262 rmse: 0.905386 (28.85126893734597 steps/sec)\n",
            "Step #7000\tEpoch   2 Batch  749/3125   Loss: 0.783174 rmse: 0.887760 (28.428153625614662 steps/sec)\n",
            "Step #7050\tEpoch   2 Batch  799/3125   Loss: 0.887339 rmse: 0.902768 (28.81604589787218 steps/sec)\n",
            "Step #7100\tEpoch   2 Batch  849/3125   Loss: 0.943184 rmse: 0.903573 (28.894534189662817 steps/sec)\n",
            "Step #7150\tEpoch   2 Batch  899/3125   Loss: 0.886890 rmse: 0.902003 (28.738609023324 steps/sec)\n",
            "Step #7200\tEpoch   2 Batch  949/3125   Loss: 0.712079 rmse: 0.901295 (28.389685097686876 steps/sec)\n",
            "Step #7250\tEpoch   2 Batch  999/3125   Loss: 0.865793 rmse: 0.903061 (28.712577264709818 steps/sec)\n",
            "Step #7300\tEpoch   2 Batch 1049/3125   Loss: 0.881799 rmse: 0.910019 (27.854001421420683 steps/sec)\n",
            "Step #7350\tEpoch   2 Batch 1099/3125   Loss: 0.770080 rmse: 0.898981 (28.942618000589576 steps/sec)\n",
            "Step #7400\tEpoch   2 Batch 1149/3125   Loss: 0.742580 rmse: 0.907285 (28.882317425200632 steps/sec)\n",
            "Step #7450\tEpoch   2 Batch 1199/3125   Loss: 0.825624 rmse: 0.895913 (28.51104291192344 steps/sec)\n",
            "Step #7500\tEpoch   2 Batch 1249/3125   Loss: 0.917420 rmse: 0.908311 (29.240010038760772 steps/sec)\n",
            "Step #7550\tEpoch   2 Batch 1299/3125   Loss: 0.796156 rmse: 0.913836 (28.997608596607787 steps/sec)\n",
            "Step #7600\tEpoch   2 Batch 1349/3125   Loss: 0.841506 rmse: 0.884193 (28.47762353327784 steps/sec)\n",
            "Step #7650\tEpoch   2 Batch 1399/3125   Loss: 0.811636 rmse: 0.902818 (28.128981548484102 steps/sec)\n",
            "Step #7700\tEpoch   2 Batch 1449/3125   Loss: 0.828912 rmse: 0.902986 (28.342707012115394 steps/sec)\n",
            "Step #7750\tEpoch   2 Batch 1499/3125   Loss: 0.844701 rmse: 0.900619 (29.00353991798277 steps/sec)\n",
            "Step #7800\tEpoch   2 Batch 1549/3125   Loss: 0.906064 rmse: 0.900656 (28.850745016143964 steps/sec)\n",
            "Step #7850\tEpoch   2 Batch 1599/3125   Loss: 0.828985 rmse: 0.896219 (28.905960440160246 steps/sec)\n",
            "Step #7900\tEpoch   2 Batch 1649/3125   Loss: 0.869968 rmse: 0.902388 (28.45919746266036 steps/sec)\n",
            "Step #7950\tEpoch   2 Batch 1699/3125   Loss: 0.844686 rmse: 0.896557 (28.60995049350293 steps/sec)\n",
            "Step #8000\tEpoch   2 Batch 1749/3125   Loss: 0.821494 rmse: 0.896028 (28.920637840704757 steps/sec)\n",
            "Step #8050\tEpoch   2 Batch 1799/3125   Loss: 0.916008 rmse: 0.902295 (28.540026902163113 steps/sec)\n",
            "Step #8100\tEpoch   2 Batch 1849/3125   Loss: 0.770564 rmse: 0.897090 (28.493583973554653 steps/sec)\n",
            "Step #8150\tEpoch   2 Batch 1899/3125   Loss: 0.874617 rmse: 0.896693 (28.630925247027932 steps/sec)\n",
            "Step #8200\tEpoch   2 Batch 1949/3125   Loss: 0.803304 rmse: 0.891304 (28.263496424933578 steps/sec)\n",
            "Step #8250\tEpoch   2 Batch 1999/3125   Loss: 0.903055 rmse: 0.901691 (28.50919412647132 steps/sec)\n",
            "Step #8300\tEpoch   2 Batch 2049/3125   Loss: 0.775965 rmse: 0.904795 (28.576127649862205 steps/sec)\n",
            "Step #8350\tEpoch   2 Batch 2099/3125   Loss: 0.858071 rmse: 0.891860 (27.91035901006723 steps/sec)\n",
            "Step #8400\tEpoch   2 Batch 2149/3125   Loss: 0.750037 rmse: 0.891049 (28.411219410026956 steps/sec)\n",
            "Step #8450\tEpoch   2 Batch 2199/3125   Loss: 0.738952 rmse: 0.895948 (28.845022813012523 steps/sec)\n",
            "Step #8500\tEpoch   2 Batch 2249/3125   Loss: 0.754966 rmse: 0.893289 (28.712247055838876 steps/sec)\n",
            "Step #8550\tEpoch   2 Batch 2299/3125   Loss: 0.875809 rmse: 0.907456 (29.057767976476136 steps/sec)\n",
            "Step #8600\tEpoch   2 Batch 2349/3125   Loss: 0.796668 rmse: 0.901785 (29.276012161856553 steps/sec)\n",
            "Step #8650\tEpoch   2 Batch 2399/3125   Loss: 0.735892 rmse: 0.896354 (28.76441579824178 steps/sec)\n",
            "Step #8700\tEpoch   2 Batch 2449/3125   Loss: 0.776861 rmse: 0.889484 (28.73628959037929 steps/sec)\n",
            "Step #8750\tEpoch   2 Batch 2499/3125   Loss: 0.907294 rmse: 0.902241 (28.000159150074516 steps/sec)\n",
            "Step #8800\tEpoch   2 Batch 2549/3125   Loss: 0.647734 rmse: 0.901658 (17.92210287173832 steps/sec)\n",
            "Step #8850\tEpoch   2 Batch 2599/3125   Loss: 0.953559 rmse: 0.905403 (28.824224558108696 steps/sec)\n",
            "Step #8900\tEpoch   2 Batch 2649/3125   Loss: 0.880277 rmse: 0.896915 (28.616637983875414 steps/sec)\n",
            "Step #8950\tEpoch   2 Batch 2699/3125   Loss: 0.739316 rmse: 0.890415 (28.458950295031567 steps/sec)\n",
            "Step #9000\tEpoch   2 Batch 2749/3125   Loss: 0.950835 rmse: 0.890180 (28.639726608078522 steps/sec)\n",
            "Step #9050\tEpoch   2 Batch 2799/3125   Loss: 0.825436 rmse: 0.902838 (27.835131867509066 steps/sec)\n",
            "Step #9100\tEpoch   2 Batch 2849/3125   Loss: 0.825576 rmse: 0.896044 (28.74962454779515 steps/sec)\n",
            "Step #9150\tEpoch   2 Batch 2899/3125   Loss: 0.832226 rmse: 0.890297 (29.06890063758435 steps/sec)\n",
            "Step #9200\tEpoch   2 Batch 2949/3125   Loss: 0.853381 rmse: 0.893906 (28.612565777185527 steps/sec)\n",
            "Step #9250\tEpoch   2 Batch 2999/3125   Loss: 0.729469 rmse: 0.893221 (28.99227288198249 steps/sec)\n",
            "Step #9300\tEpoch   2 Batch 3049/3125   Loss: 0.763348 rmse: 0.886822 (29.13779092086669 steps/sec)\n",
            "Step #9350\tEpoch   2 Batch 3099/3125   Loss: 0.871267 rmse: 0.890460 (28.059009828236984 steps/sec)\n",
            "\n",
            "Train time for epoch #3 (9375 total steps): 110.2358865737915\n",
            "Model test set loss: 0.815560 rmse: 0.902727\n",
            "best rmse = 0.9027273058891296\n",
            "Step #9400\tEpoch   3 Batch   24/3125   Loss: 0.709050 rmse: 0.902441 (51.92574339796056 steps/sec)\n",
            "Step #9450\tEpoch   3 Batch   74/3125   Loss: 0.849421 rmse: 0.887555 (28.679323310018656 steps/sec)\n",
            "Step #9500\tEpoch   3 Batch  124/3125   Loss: 0.690320 rmse: 0.899825 (28.82275879092274 steps/sec)\n",
            "Step #9550\tEpoch   3 Batch  174/3125   Loss: 0.754771 rmse: 0.893970 (28.95441811429415 steps/sec)\n",
            "Step #9600\tEpoch   3 Batch  224/3125   Loss: 0.609419 rmse: 0.896248 (26.006691060175147 steps/sec)\n",
            "Step #9650\tEpoch   3 Batch  274/3125   Loss: 0.783384 rmse: 0.895429 (28.514589995489935 steps/sec)\n",
            "Step #9700\tEpoch   3 Batch  324/3125   Loss: 0.768336 rmse: 0.899897 (28.44305176572165 steps/sec)\n",
            "Step #9750\tEpoch   3 Batch  374/3125   Loss: 0.804172 rmse: 0.899760 (28.899869829096602 steps/sec)\n",
            "Step #9800\tEpoch   3 Batch  424/3125   Loss: 0.855231 rmse: 0.901807 (28.714531155952006 steps/sec)\n",
            "Step #9850\tEpoch   3 Batch  474/3125   Loss: 0.781675 rmse: 0.892536 (28.919070530941575 steps/sec)\n",
            "Step #9900\tEpoch   3 Batch  524/3125   Loss: 0.831780 rmse: 0.889105 (29.08104189391084 steps/sec)\n",
            "Step #9950\tEpoch   3 Batch  574/3125   Loss: 0.881159 rmse: 0.899905 (28.38156677088276 steps/sec)\n",
            "Step #10000\tEpoch   3 Batch  624/3125   Loss: 0.624903 rmse: 0.896010 (28.059268868858585 steps/sec)\n",
            "Step #10050\tEpoch   3 Batch  674/3125   Loss: 0.816314 rmse: 0.899016 (29.23706277064455 steps/sec)\n",
            "Step #10100\tEpoch   3 Batch  724/3125   Loss: 0.653462 rmse: 0.892386 (29.086208630224856 steps/sec)\n",
            "Step #10150\tEpoch   3 Batch  774/3125   Loss: 0.740010 rmse: 0.884095 (29.37893345530474 steps/sec)\n",
            "Step #10200\tEpoch   3 Batch  824/3125   Loss: 0.815976 rmse: 0.895300 (29.046362224128035 steps/sec)\n",
            "Step #10250\tEpoch   3 Batch  874/3125   Loss: 0.750409 rmse: 0.895056 (28.705766278904555 steps/sec)\n",
            "Step #10300\tEpoch   3 Batch  924/3125   Loss: 0.895311 rmse: 0.901072 (28.568645670529172 steps/sec)\n",
            "Step #10350\tEpoch   3 Batch  974/3125   Loss: 0.752248 rmse: 0.896403 (29.062326341973794 steps/sec)\n",
            "Step #10400\tEpoch   3 Batch 1024/3125   Loss: 0.786029 rmse: 0.892229 (28.89185118730427 steps/sec)\n",
            "Step #10450\tEpoch   3 Batch 1074/3125   Loss: 0.850496 rmse: 0.892906 (28.74797719794022 steps/sec)\n",
            "Step #10500\tEpoch   3 Batch 1124/3125   Loss: 0.795995 rmse: 0.899255 (29.444994362752325 steps/sec)\n",
            "Step #10550\tEpoch   3 Batch 1174/3125   Loss: 0.732970 rmse: 0.895331 (28.916881367337048 steps/sec)\n",
            "Step #10600\tEpoch   3 Batch 1224/3125   Loss: 0.764380 rmse: 0.891507 (28.57895095460678 steps/sec)\n",
            "Step #10650\tEpoch   3 Batch 1274/3125   Loss: 0.903987 rmse: 0.910374 (28.62083243601176 steps/sec)\n",
            "Step #10700\tEpoch   3 Batch 1324/3125   Loss: 0.700783 rmse: 0.889109 (28.82565085306471 steps/sec)\n",
            "Step #10750\tEpoch   3 Batch 1374/3125   Loss: 0.745729 rmse: 0.886491 (28.340696154890882 steps/sec)\n",
            "Step #10800\tEpoch   3 Batch 1424/3125   Loss: 0.811030 rmse: 0.892514 (28.836308950474308 steps/sec)\n",
            "Step #10850\tEpoch   3 Batch 1474/3125   Loss: 0.710418 rmse: 0.895924 (29.507744623563624 steps/sec)\n",
            "Step #10900\tEpoch   3 Batch 1524/3125   Loss: 0.715465 rmse: 0.885977 (28.79555429964594 steps/sec)\n",
            "Step #10950\tEpoch   3 Batch 1574/3125   Loss: 0.779598 rmse: 0.901561 (29.19163272822736 steps/sec)\n",
            "Step #11000\tEpoch   3 Batch 1624/3125   Loss: 0.848890 rmse: 0.881505 (29.67914317415031 steps/sec)\n",
            "Step #11050\tEpoch   3 Batch 1674/3125   Loss: 0.714948 rmse: 0.895202 (28.81729714993266 steps/sec)\n",
            "Step #11100\tEpoch   3 Batch 1724/3125   Loss: 0.892706 rmse: 0.892780 (28.69263291716297 steps/sec)\n",
            "Step #11150\tEpoch   3 Batch 1774/3125   Loss: 0.771087 rmse: 0.887923 (28.40353500187379 steps/sec)\n",
            "Step #11200\tEpoch   3 Batch 1824/3125   Loss: 0.700760 rmse: 0.894643 (28.776454031814545 steps/sec)\n",
            "Step #11250\tEpoch   3 Batch 1874/3125   Loss: 0.865043 rmse: 0.892432 (28.6517428820198 steps/sec)\n",
            "Step #11300\tEpoch   3 Batch 1924/3125   Loss: 0.978729 rmse: 0.887663 (28.444440586420278 steps/sec)\n",
            "Step #11350\tEpoch   3 Batch 1974/3125   Loss: 0.776921 rmse: 0.886599 (29.10095258817352 steps/sec)\n",
            "Step #11400\tEpoch   3 Batch 2024/3125   Loss: 0.860594 rmse: 0.896617 (28.554373826319207 steps/sec)\n",
            "Step #11450\tEpoch   3 Batch 2074/3125   Loss: 0.843536 rmse: 0.885656 (28.41310170407996 steps/sec)\n",
            "Step #11500\tEpoch   3 Batch 2124/3125   Loss: 0.634453 rmse: 0.894692 (28.893542933423053 steps/sec)\n",
            "Step #11550\tEpoch   3 Batch 2174/3125   Loss: 0.729246 rmse: 0.881977 (29.17517721557377 steps/sec)\n",
            "Step #11600\tEpoch   3 Batch 2224/3125   Loss: 0.697197 rmse: 0.892475 (28.289391505164428 steps/sec)\n",
            "Step #11650\tEpoch   3 Batch 2274/3125   Loss: 0.823443 rmse: 0.892219 (18.19953909992142 steps/sec)\n",
            "Step #11700\tEpoch   3 Batch 2324/3125   Loss: 0.661057 rmse: 0.898527 (29.24663642734369 steps/sec)\n",
            "Step #11750\tEpoch   3 Batch 2374/3125   Loss: 0.752326 rmse: 0.889044 (29.0723501094189 steps/sec)\n",
            "Step #11800\tEpoch   3 Batch 2424/3125   Loss: 0.748355 rmse: 0.889149 (29.333172574394485 steps/sec)\n",
            "Step #11850\tEpoch   3 Batch 2474/3125   Loss: 0.858555 rmse: 0.885847 (29.311582742892874 steps/sec)\n",
            "Step #11900\tEpoch   3 Batch 2524/3125   Loss: 0.763588 rmse: 0.894299 (28.56856005140606 steps/sec)\n",
            "Step #11950\tEpoch   3 Batch 2574/3125   Loss: 0.885456 rmse: 0.900664 (28.820489126722766 steps/sec)\n",
            "Step #12000\tEpoch   3 Batch 2624/3125   Loss: 0.943755 rmse: 0.900056 (28.695239781499602 steps/sec)\n",
            "Step #12050\tEpoch   3 Batch 2674/3125   Loss: 0.786759 rmse: 0.887847 (27.81025682508656 steps/sec)\n",
            "Step #12100\tEpoch   3 Batch 2724/3125   Loss: 0.758814 rmse: 0.876168 (29.048985478499215 steps/sec)\n",
            "Step #12150\tEpoch   3 Batch 2774/3125   Loss: 0.729530 rmse: 0.890599 (29.010071588956112 steps/sec)\n",
            "Step #12200\tEpoch   3 Batch 2824/3125   Loss: 0.801275 rmse: 0.903008 (28.50000801801907 steps/sec)\n",
            "Step #12250\tEpoch   3 Batch 2874/3125   Loss: 0.829368 rmse: 0.881777 (27.949609586780912 steps/sec)\n",
            "Step #12300\tEpoch   3 Batch 2924/3125   Loss: 0.818528 rmse: 0.885044 (28.460429502844413 steps/sec)\n",
            "Step #12350\tEpoch   3 Batch 2974/3125   Loss: 0.719278 rmse: 0.888556 (28.49311167471241 steps/sec)\n",
            "Step #12400\tEpoch   3 Batch 3024/3125   Loss: 0.714375 rmse: 0.884723 (29.238041051026514 steps/sec)\n",
            "Step #12450\tEpoch   3 Batch 3074/3125   Loss: 0.784549 rmse: 0.883051 (28.587587888192875 steps/sec)\n",
            "Step #12500\tEpoch   3 Batch 3124/3125   Loss: 0.845768 rmse: 0.882604 (28.765859854439114 steps/sec)\n",
            "\n",
            "Train time for epoch #4 (12500 total steps): 110.00509834289551\n",
            "Model test set loss: 0.808088 rmse: 0.898937\n",
            "best rmse = 0.8989371657371521\n",
            "Step #12550\tEpoch   4 Batch   49/3125   Loss: 0.871133 rmse: 0.898335 (27.545360847626352 steps/sec)\n",
            "Step #12600\tEpoch   4 Batch   99/3125   Loss: 0.965264 rmse: 0.881107 (28.440849219906553 steps/sec)\n",
            "Step #12650\tEpoch   4 Batch  149/3125   Loss: 0.765069 rmse: 0.888225 (29.04882452900544 steps/sec)\n",
            "Step #12700\tEpoch   4 Batch  199/3125   Loss: 0.816448 rmse: 0.891585 (28.824367181252683 steps/sec)\n",
            "Step #12750\tEpoch   4 Batch  249/3125   Loss: 0.849144 rmse: 0.888475 (29.48409801788994 steps/sec)\n",
            "Step #12800\tEpoch   4 Batch  299/3125   Loss: 0.764828 rmse: 0.893528 (28.730435573619726 steps/sec)\n",
            "Step #12850\tEpoch   4 Batch  349/3125   Loss: 0.858607 rmse: 0.894492 (28.827667716548206 steps/sec)\n",
            "Step #12900\tEpoch   4 Batch  399/3125   Loss: 0.895558 rmse: 0.891683 (29.30625372764739 steps/sec)\n",
            "Step #12950\tEpoch   4 Batch  449/3125   Loss: 0.794131 rmse: 0.897485 (29.38467595829556 steps/sec)\n",
            "Step #13000\tEpoch   4 Batch  499/3125   Loss: 0.777560 rmse: 0.879100 (28.391349294153134 steps/sec)\n",
            "Step #13050\tEpoch   4 Batch  549/3125   Loss: 0.774811 rmse: 0.886239 (29.355020226480594 steps/sec)\n",
            "Step #13100\tEpoch   4 Batch  599/3125   Loss: 0.690156 rmse: 0.899305 (29.470913880623485 steps/sec)\n",
            "Step #13150\tEpoch   4 Batch  649/3125   Loss: 0.746281 rmse: 0.892444 (29.241583788982815 steps/sec)\n",
            "Step #13200\tEpoch   4 Batch  699/3125   Loss: 0.771883 rmse: 0.892598 (29.65949912032087 steps/sec)\n",
            "Step #13250\tEpoch   4 Batch  749/3125   Loss: 0.758594 rmse: 0.874757 (29.089742912195153 steps/sec)\n",
            "Step #13300\tEpoch   4 Batch  799/3125   Loss: 0.855268 rmse: 0.890218 (29.261404702358995 steps/sec)\n",
            "Step #13350\tEpoch   4 Batch  849/3125   Loss: 0.898913 rmse: 0.890640 (29.610034320865356 steps/sec)\n",
            "Step #13400\tEpoch   4 Batch  899/3125   Loss: 0.863856 rmse: 0.889154 (29.020505091781594 steps/sec)\n",
            "Step #13450\tEpoch   4 Batch  949/3125   Loss: 0.682301 rmse: 0.888608 (29.33234791993199 steps/sec)\n",
            "Step #13500\tEpoch   4 Batch  999/3125   Loss: 0.865780 rmse: 0.888929 (29.93021783823012 steps/sec)\n",
            "Step #13550\tEpoch   4 Batch 1049/3125   Loss: 0.847601 rmse: 0.897404 (29.590940889853766 steps/sec)\n",
            "Step #13600\tEpoch   4 Batch 1099/3125   Loss: 0.746432 rmse: 0.885235 (29.390169455610746 steps/sec)\n",
            "Step #13650\tEpoch   4 Batch 1149/3125   Loss: 0.736361 rmse: 0.894545 (29.515518942889006 steps/sec)\n",
            "Step #13700\tEpoch   4 Batch 1199/3125   Loss: 0.834201 rmse: 0.885912 (29.51090867591603 steps/sec)\n",
            "Step #13750\tEpoch   4 Batch 1249/3125   Loss: 0.896828 rmse: 0.894113 (29.586858010304567 steps/sec)\n",
            "Step #13800\tEpoch   4 Batch 1299/3125   Loss: 0.767625 rmse: 0.899457 (29.982002095013897 steps/sec)\n",
            "Step #13850\tEpoch   4 Batch 1349/3125   Loss: 0.819069 rmse: 0.871791 (29.313225666404726 steps/sec)\n",
            "Step #13900\tEpoch   4 Batch 1399/3125   Loss: 0.794694 rmse: 0.890220 (29.262286618462507 steps/sec)\n",
            "Step #13950\tEpoch   4 Batch 1449/3125   Loss: 0.773184 rmse: 0.889951 (29.306986813091296 steps/sec)\n",
            "Step #14000\tEpoch   4 Batch 1499/3125   Loss: 0.833828 rmse: 0.889514 (29.210018881369397 steps/sec)\n",
            "Step #14050\tEpoch   4 Batch 1549/3125   Loss: 0.890461 rmse: 0.887356 (29.502896054354547 steps/sec)\n",
            "Step #14100\tEpoch   4 Batch 1599/3125   Loss: 0.796626 rmse: 0.883218 (29.227576847137474 steps/sec)\n",
            "Step #14150\tEpoch   4 Batch 1649/3125   Loss: 0.842393 rmse: 0.889069 (29.280144600201414 steps/sec)\n",
            "Step #14200\tEpoch   4 Batch 1699/3125   Loss: 0.816918 rmse: 0.883970 (29.270042419643367 steps/sec)\n",
            "Step #14250\tEpoch   4 Batch 1749/3125   Loss: 0.801483 rmse: 0.884152 (29.019798315257813 steps/sec)\n",
            "Step #14300\tEpoch   4 Batch 1799/3125   Loss: 0.888260 rmse: 0.890323 (29.135645427250843 steps/sec)\n",
            "Step #14350\tEpoch   4 Batch 1849/3125   Loss: 0.757837 rmse: 0.886409 (29.391944780224595 steps/sec)\n",
            "Step #14400\tEpoch   4 Batch 1899/3125   Loss: 0.867972 rmse: 0.884331 (29.198472990167776 steps/sec)\n",
            "Step #14450\tEpoch   4 Batch 1949/3125   Loss: 0.776466 rmse: 0.879866 (29.638595048692384 steps/sec)\n",
            "Step #14500\tEpoch   4 Batch 1999/3125   Loss: 0.875918 rmse: 0.889634 (27.247184077052623 steps/sec)\n",
            "Step #14550\tEpoch   4 Batch 2049/3125   Loss: 0.736437 rmse: 0.893114 (18.92225663631776 steps/sec)\n",
            "Step #14600\tEpoch   4 Batch 2099/3125   Loss: 0.831070 rmse: 0.878733 (29.284723935726856 steps/sec)\n",
            "Step #14650\tEpoch   4 Batch 2149/3125   Loss: 0.748319 rmse: 0.879301 (29.783692614804476 steps/sec)\n",
            "Step #14700\tEpoch   4 Batch 2199/3125   Loss: 0.700261 rmse: 0.885038 (29.382144040529568 steps/sec)\n",
            "Step #14750\tEpoch   4 Batch 2249/3125   Loss: 0.736792 rmse: 0.879612 (29.70407144324129 steps/sec)\n",
            "Step #14800\tEpoch   4 Batch 2299/3125   Loss: 0.852007 rmse: 0.896089 (29.322804175477202 steps/sec)\n",
            "Step #14850\tEpoch   4 Batch 2349/3125   Loss: 0.780555 rmse: 0.890553 (28.899443701914404 steps/sec)\n",
            "Step #14900\tEpoch   4 Batch 2399/3125   Loss: 0.711537 rmse: 0.884935 (29.40715710192368 steps/sec)\n",
            "Step #14950\tEpoch   4 Batch 2449/3125   Loss: 0.750301 rmse: 0.877680 (29.38033697098212 steps/sec)\n",
            "Step #15000\tEpoch   4 Batch 2499/3125   Loss: 0.899955 rmse: 0.890997 (29.296108970832577 steps/sec)\n",
            "Step #15050\tEpoch   4 Batch 2549/3125   Loss: 0.616744 rmse: 0.891399 (29.503771833776234 steps/sec)\n",
            "Step #15100\tEpoch   4 Batch 2599/3125   Loss: 0.914665 rmse: 0.893172 (29.54182499462947 steps/sec)\n",
            "Step #15150\tEpoch   4 Batch 2649/3125   Loss: 0.864991 rmse: 0.887630 (29.117651918355968 steps/sec)\n",
            "Step #15200\tEpoch   4 Batch 2699/3125   Loss: 0.742383 rmse: 0.879353 (29.32340688402727 steps/sec)\n",
            "Step #15250\tEpoch   4 Batch 2749/3125   Loss: 0.900831 rmse: 0.877074 (29.328217140058587 steps/sec)\n",
            "Step #15300\tEpoch   4 Batch 2799/3125   Loss: 0.817185 rmse: 0.892249 (29.0642153417722 steps/sec)\n",
            "Step #15350\tEpoch   4 Batch 2849/3125   Loss: 0.789893 rmse: 0.882590 (29.65540988173341 steps/sec)\n",
            "Step #15400\tEpoch   4 Batch 2899/3125   Loss: 0.800044 rmse: 0.878383 (29.422071463935882 steps/sec)\n",
            "Step #15450\tEpoch   4 Batch 2949/3125   Loss: 0.833270 rmse: 0.882890 (29.389708153462298 steps/sec)\n",
            "Step #15500\tEpoch   4 Batch 2999/3125   Loss: 0.717631 rmse: 0.882290 (29.333156162908207 steps/sec)\n",
            "Step #15550\tEpoch   4 Batch 3049/3125   Loss: 0.737140 rmse: 0.875762 (29.952677628142677 steps/sec)\n",
            "Step #15600\tEpoch   4 Batch 3099/3125   Loss: 0.855426 rmse: 0.880244 (29.2558245492007 steps/sec)\n",
            "\n",
            "Train time for epoch #5 (15625 total steps): 107.94252872467041\n",
            "Model test set loss: 0.800669 rmse: 0.894407\n",
            "best rmse = 0.8944066166877747\n",
            "INFO:tensorflow:Assets written to: ./models/export/assets\n"
          ]
        }
      ],
      "source": [
        "mrs_net = mrs_network()\n",
        "mrs_net.training(features, targets_values, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwIVOm244XiR"
      },
      "source": [
        "### Visualize Training Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "pZe2e2dN4XiR",
        "outputId": "baa0b66b-c264-4301-ba09-5d3255d3a724"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(mrs_net.losses['train'], label='Training loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLOu8rtU4XiS"
      },
      "source": [
        "### Visualize Testing Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "PPlj8L-g4XiS",
        "outputId": "c75f8d07-2478-458a-f5f6-5ddf3862ca04"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(mrs_net.losses['test'], label='Test loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQaqg3f14XiS"
      },
      "source": [
        "### Rate Given User and Movie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q--7SL7g4XiS"
      },
      "outputs": [],
      "source": [
        "def rating_movie(mrs_net, user_id_val, movie_id_val):\n",
        "    categories = np.zeros([1, 18])\n",
        "    categories[0] = movies.values[movieid2idx[movie_id_val]][2]\n",
        "    \n",
        "    titles = np.zeros([1, sentences_size])\n",
        "    titles[0] = movies.values[movieid2idx[movie_id_val]][1]\n",
        "    \n",
        "    inference_val = mrs_net.model([np.reshape(users.values[user_id_val-1][0], [1, 1]),\n",
        "              np.reshape(users.values[user_id_val-1][1], [1, 1]),\n",
        "              np.reshape(users.values[user_id_val-1][2], [1, 1]),\n",
        "              np.reshape(users.values[user_id_val-1][3], [1, 1]),\n",
        "              np.reshape(movies.values[movieid2idx[movie_id_val]][0], [1, 1]),\n",
        "              categories,  \n",
        "              titles])\n",
        "\n",
        "    return (inference_val.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA6_ay9Z4XiT"
      },
      "source": [
        "### Save User's Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjCt7qM04XiT"
      },
      "outputs": [],
      "source": [
        "user_layer_model = keras.models.Model(inputs=[mrs_net.model.input[0], mrs_net.model.input[1], mrs_net.model.input[2], mrs_net.model.input[3]], \n",
        "                                 outputs=mrs_net.model.get_layer(\"user_combine_layer_flat\").output)\n",
        "users_matrics = []\n",
        "\n",
        "for item in users.values:\n",
        "    user_combine_layer_flat_val = user_layer_model([np.reshape(item.take(0), [1, 1]), \n",
        "                                                    np.reshape(item.take(1), [1, 1]), \n",
        "                                                    np.reshape(item.take(2), [1, 1]), \n",
        "                                                    np.reshape(item.take(3), [1, 1])])  \n",
        "    users_matrics.append(user_combine_layer_flat_val)\n",
        "\n",
        "pickle.dump((np.array(users_matrics).reshape(-1, 200)), open('users_matrics.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMEWiVyW4XiT",
        "outputId": "19b4fb45-7800-48df-bf95-5712aa4126b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.00321702 -0.09089328 -0.02635128 ... -0.06640862 -0.00116399\n",
            "  -0.05063942]\n",
            " [-0.01665238 -0.01922891 -0.07042468 ... -0.02603988  0.04352098\n",
            "  -0.04237579]\n",
            " [ 0.00117174 -0.01110188 -0.05033495 ... -0.02664727  0.04094043\n",
            "  -0.03344682]\n",
            " ...\n",
            " [-0.01405391 -0.11476086 -0.07478969 ... -0.04480696 -0.02455059\n",
            "  -0.06973559]\n",
            " [-0.04776129 -0.09942249 -0.05475966 ... -0.05797588 -0.0311058\n",
            "  -0.08214524]\n",
            " [-0.05255647 -0.00931738 -0.05161802 ...  0.00208724 -0.06019311\n",
            "  -0.01966193]]\n"
          ]
        }
      ],
      "source": [
        "users_matrics = pickle.load(open('users_matrics.pkl', mode='rb'))\n",
        "print(users_matrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ5lkqEj4XiT"
      },
      "source": [
        "### Save Movie's Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8YuTtRL4XiT"
      },
      "outputs": [],
      "source": [
        "movie_layer_model = keras.models.Model(inputs=[mrs_net.model.input[4], mrs_net.model.input[5], mrs_net.model.input[6]], \n",
        "                                 outputs=mrs_net.model.get_layer(\"movie_combine_layer_flat\").output)\n",
        "movie_matrics = []\n",
        "\n",
        "for item in movies.values:\n",
        "    categories = np.zeros([1, 18])\n",
        "    categories[0] = item.take(2)\n",
        "\n",
        "    titles = np.zeros([1, sentences_size])\n",
        "    titles[0] = item.take(1)\n",
        "\n",
        "    movie_combine_layer_flat_val = movie_layer_model([np.reshape(item.take(0), [1, 1]), categories, titles])  \n",
        "    movie_matrics.append(movie_combine_layer_flat_val)\n",
        "\n",
        "pickle.dump((np.array(movie_matrics).reshape(-1, 200)), open('movie_matrics.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaSVV2pl4XiU",
        "outputId": "5955f43a-663f-4842-c7a5-d44096e5f4e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.49142566 -0.40400138 -0.5319641  ... -0.27717316 -0.40968475\n",
            "  -0.51434034]\n",
            " [-0.28648397 -0.3716132  -0.43718812 ... -0.25332248 -0.06870798\n",
            "  -0.47232157]\n",
            " [-0.20940673 -0.38718307 -0.346356   ... -0.3383206  -0.00328024\n",
            "  -0.51792294]\n",
            " ...\n",
            " [-0.40831864 -0.351856   -0.42770928 ... -0.36755925 -0.25672665\n",
            "  -0.5426193 ]\n",
            " [-0.45576802 -0.31501547 -0.45892015 ... -0.35322016 -0.3630539\n",
            "  -0.5464134 ]\n",
            " [-0.44551364 -0.3471051  -0.4095839  ... -0.33541015 -0.2747999\n",
            "  -0.5616216 ]]\n"
          ]
        }
      ],
      "source": [
        "movie_matrics = pickle.load(open('movie_matrics.pkl', mode='rb'))\n",
        "print(movie_matrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUvsF5H24XiU"
      },
      "source": [
        "### Recommend Movie\n",
        "\n",
        "#### Recommend movies with same genre\n",
        "\n",
        "The ides is to \n",
        "\n",
        "1. Compute the **cosine similarity** of the given movie and the whole movies' feature matrix\n",
        "2. Return top k max similarity values\n",
        "3. Select randomly to make sure each recommendation id distinct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mL2h2NC4XiU",
        "outputId": "e8515735-460e-403c-c499-3da2e8dfd28b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[-0.0741367  -0.05376326 -0.0402433  ... -0.06964973 -0.07217798\n",
            "  -0.0726875 ]\n",
            " [-0.06094783 -0.0697391  -0.07440794 ... -0.06001851 -0.04988762\n",
            "  -0.05663171]\n",
            " [-0.08025235 -0.08204527 -0.06656189 ... -0.07295733 -0.07267717\n",
            "  -0.0668254 ]\n",
            " ...\n",
            " [-0.04181447 -0.04753998 -0.06501766 ... -0.06269713 -0.05593793\n",
            "  -0.05472364]\n",
            " [-0.06180523 -0.01289414 -0.00063039 ... -0.04379164 -0.05749525\n",
            "  -0.04483481]\n",
            " [-0.07759362 -0.08863862 -0.09953322 ... -0.09255833 -0.08653309\n",
            "  -0.09163103]], shape=(200, 3883), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# print(movieid2idx)\n",
        "# print(tf.reshape(movie_matrics[movieid2idx[2]], [1, 200]))\n",
        "norm_movie_matrics = tf.sqrt(tf.reduce_sum(tf.square(movie_matrics), 1, keepdims=True))\n",
        "normalized_movie_matrics = movie_matrics / norm_movie_matrics\n",
        "print(tf.transpose(normalized_movie_matrics))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tm0RJlSJ4XiV"
      },
      "outputs": [],
      "source": [
        "def recommend_same_genre_movie(movie_id_val, top_k = 20):\n",
        "   \n",
        "    norm_movie_matrics = tf.sqrt(tf.reduce_sum(tf.square(movie_matrics), 1, keepdims=True))\n",
        "    normalized_movie_matrics = movie_matrics / norm_movie_matrics\n",
        "\n",
        "    # Recommend movies with same genre\n",
        "    probs_embeddings = tf.reshape(movie_matrics[movieid2idx[movie_id_val]], [1, 200])\n",
        "    probs_similarity = tf.matmul(probs_embeddings, tf.transpose(normalized_movie_matrics))\n",
        "    sim = (probs_similarity.numpy())\n",
        "\n",
        "    print(f\"The movie you're watching is：{ movies_origin[movieid2idx[movie_id_val]] }\")\n",
        "    print(\"Here are recommendations for you：\")\n",
        "    p = np.squeeze(sim)\n",
        "    p[np.argsort(p)[:-top_k]] = 0\n",
        "    p = p / np.sum(p)\n",
        "    results = set()\n",
        "    while len(results) != 5:\n",
        "        c = np.random.choice(3883, 1, p=p)[0]\n",
        "        results.add(c)\n",
        "    for val in (results):\n",
        "        print(val)\n",
        "        print(movies_origin[val])\n",
        "        \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQk2Pwn24XiV",
        "outputId": "ca6f58a8-04df-441a-a630-1135e8aab3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The movie you're watching is：[1 'Toy Story (1995)' \"Animation|Children's|Comedy\"]\n",
            "Here are recommendations for you：\n",
            "3045\n",
            "[3114 'Toy Story 2 (1999)' \"Animation|Children's|Comedy\"]\n",
            "935\n",
            "[947 'My Man Godfrey (1936)' 'Comedy']\n",
            "886\n",
            "[898 'Philadelphia Story, The (1940)' 'Comedy|Romance']\n",
            "2327\n",
            "[2396 'Shakespeare in Love (1998)' 'Comedy|Romance']\n",
            "2719\n",
            "[2788 'And Now for Something Completely Different (1971)' 'Comedy']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{886, 935, 2327, 2719, 3045}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "recommend_same_genre_movie(1, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFTntViK4XiV"
      },
      "source": [
        "#### Recommend movies you may like\n",
        "\n",
        "1. Compute the **cosine similarity** of the given user and the whole movies' feature matrix\n",
        "2. Return top k max similarity values\n",
        "3. Select randomly to make sure each recommendation id distinct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ak6G8Lkz4XiV"
      },
      "outputs": [],
      "source": [
        "def recommend_your_favorite_movie(user_id_val, top_k = 10):\n",
        "    # Recommend your favorite movies\n",
        "    probs_embeddings = tf.reshape(users_matrics[user_id_val-1], [1, 200])\n",
        "    probs_similarity = tf.matmul(probs_embeddings, tf.transpose(movie_matrics))\n",
        "    sim = (probs_similarity.numpy())\n",
        "    \n",
        "    print(\"Here are recommendations for you：\")\n",
        "    p = np.squeeze(sim)\n",
        "    p[np.argsort(p)[:-top_k]] = 0\n",
        "    p = p / np.sum(p)\n",
        "    results = set()\n",
        "    while len(results) != 5:\n",
        "        c = np.random.choice(3883, 1, p=p)[0]\n",
        "        results.add(c)\n",
        "    for val in (results):\n",
        "        print(val)\n",
        "        print(movies_origin[val])\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1y1KAd54XiW",
        "outputId": "67808793-022d-4f31-a2f6-17539cb92db4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are recommendations for you：\n",
            "2434\n",
            "[2503 'Apple, The (Sib) (1998)' 'Drama']\n",
            "49\n",
            "[50 'Usual Suspects, The (1995)' 'Crime|Thriller']\n",
            "52\n",
            "[53 'Lamerica (1994)' 'Drama']\n",
            "2836\n",
            "[2905 'Sanjuro (1962)' 'Action|Adventure']\n",
            "1950\n",
            "[2019\n",
            " 'Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)'\n",
            " 'Action|Drama']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{49, 52, 1950, 2434, 2836}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "recommend_your_favorite_movie(2434, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m48jjo_q4XiW"
      },
      "source": [
        "#### Recommend other favorite movies according to the given movie\n",
        "\n",
        "1. Select top k users who like the given movie in order to obtain their feature matrix\n",
        "2. Calculate rating of all movies given by these users\n",
        "3. Recommend movies with highest ratings\n",
        "4. Select movies with same ratings randomly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swDk2DRg4XiW"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def recommend_other_favorite_movie(movie_id_val, top_k = 20):\n",
        "    probs_movie_embeddings = tf.reshape(movie_matrics[movieid2idx[movie_id_val]], [1, 200])\n",
        "    probs_user_favorite_similarity = tf.matmul(probs_movie_embeddings, tf.transpose(users_matrics))\n",
        "    favorite_user_id = np.argsort(probs_user_favorite_similarity.numpy())[0][-top_k:]\n",
        "    \n",
        "    print(f\"The movie you watching is：{ movies_origin[movieid2idx[movie_id_val]] }\")\n",
        "    print(f\"People who like the movie are：{ users_origin[favorite_user_id - 1] }\")\n",
        "    \n",
        "    probs_users_embeddings = tf.reshape(users_matrics[favorite_user_id-1], [-1, 200])\n",
        "    probs_similarity = tf.matmul(probs_users_embeddings, tf.transpose(movie_matrics))\n",
        "    sim = (probs_similarity.numpy())\n",
        "    p = np.argmax(sim, 1)\n",
        "    print(\"Other movies may like：\")\n",
        "\n",
        "    if len(set(p)) < 5:\n",
        "        results = set(p)\n",
        "    else:\n",
        "        results = set()\n",
        "        while len(results) != 5:\n",
        "            c = p[random.randrange(top_k)]\n",
        "            results.add(c)\n",
        "    for val in (results):\n",
        "        print(val)\n",
        "        print(movies_origin[val])\n",
        "        \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FkULIx94XiW",
        "outputId": "7405b422-89ce-441c-ab97-eaa5341a6329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.00321702 -0.09089328 -0.02635128 ... -0.06640862 -0.00116399\n",
            "  -0.05063942]\n",
            " [-0.01665238 -0.01922891 -0.07042468 ... -0.02603988  0.04352098\n",
            "  -0.04237579]\n",
            " [ 0.00117174 -0.01110188 -0.05033495 ... -0.02664727  0.04094043\n",
            "  -0.03344682]\n",
            " ...\n",
            " [-0.01405391 -0.11476086 -0.07478969 ... -0.04480696 -0.02455059\n",
            "  -0.06973559]\n",
            " [-0.04776129 -0.09942249 -0.05475966 ... -0.05797588 -0.0311058\n",
            "  -0.08214524]\n",
            " [-0.05255647 -0.00931738 -0.05161802 ...  0.00208724 -0.06019311\n",
            "  -0.01966193]]\n",
            "[[-0.49142566 -0.40400138 -0.5319641  ... -0.27717316 -0.40968475\n",
            "  -0.51434034]\n",
            " [-0.28648397 -0.3716132  -0.43718812 ... -0.25332248 -0.06870798\n",
            "  -0.47232157]\n",
            " [-0.20940673 -0.38718307 -0.346356   ... -0.3383206  -0.00328024\n",
            "  -0.51792294]\n",
            " ...\n",
            " [-0.40831864 -0.351856   -0.42770928 ... -0.36755925 -0.25672665\n",
            "  -0.5426193 ]\n",
            " [-0.45576802 -0.31501547 -0.45892015 ... -0.35322016 -0.3630539\n",
            "  -0.5464134 ]\n",
            " [-0.44551364 -0.3471051  -0.4095839  ... -0.33541015 -0.2747999\n",
            "  -0.5616216 ]]\n"
          ]
        }
      ],
      "source": [
        "users_matrics = pickle.load(open('users_matrics.pkl', mode='rb'))\n",
        "print(users_matrics)\n",
        "movie_matrics = pickle.load(open('movie_matrics.pkl', mode='rb'))\n",
        "print(movie_matrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpUz1dtN4XiX",
        "outputId": "b797d97d-e23e-41a9-f1d2-c6873543ac62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The movie you watching is：[1401 'Ghosts of Mississippi (1996)' 'Drama']\n",
            "People who like the movie are：[[287 'M' 50 13]\n",
            " [1701 'F' 25 4]\n",
            " [566 'M' 25 17]\n",
            " [1669 'F' 25 17]\n",
            " [3323 'M' 35 14]\n",
            " [4754 'F' 18 0]\n",
            " [2693 'M' 56 13]\n",
            " [4200 'M' 45 7]\n",
            " [1855 'M' 18 4]\n",
            " [4085 'F' 25 6]\n",
            " [445 'M' 45 12]\n",
            " [4800 'M' 18 4]\n",
            " [100 'M' 35 17]\n",
            " [2338 'M' 45 17]\n",
            " [371 'M' 18 4]\n",
            " [5861 'F' 50 1]\n",
            " [282 'M' 25 17]\n",
            " [3901 'M' 18 14]\n",
            " [446 'F' 50 0]\n",
            " [2154 'M' 25 12]]\n",
            "Other movies may like：\n",
            "2693\n",
            "[2762 'Sixth Sense, The (1999)' 'Thriller']\n",
            "847\n",
            "[858 'Godfather, The (1972)' 'Action|Crime|Drama']\n",
            "2128\n",
            "[2197 'Firelight (1997)' 'Drama']\n",
            "2836\n",
            "[2905 'Sanjuro (1962)' 'Action|Adventure']\n",
            "315\n",
            "[318 'Shawshank Redemption, The (1994)' 'Drama']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{315, 847, 2128, 2693, 2836}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "recommend_other_favorite_movie(1401, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxRGkHL-4XiX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Convolutional_Neural_Networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}